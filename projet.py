import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
from pathlib import Path
import unicodedata
import numpy as np
import re

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# APP STREAMLIT : DOSSIER UBISOFT
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
st.set_page_config(page_title="Dossier Ubisoft", page_icon="üéÆ", layout="wide")

# üîß 1) Ajoute "Conclusion" √† la navigation (mets √† jour ta liste existante)
page = st.sidebar.radio(
    "Aller vers :",
    [
        "Introduction",
        "Analyse financi√®re comparative",
        "Analyse des performances des jeux Ubisoft",
        "Perception et critique : la rupture avec les joueurs",
        "Conclusion",  # ‚Üê ajoute cette ligne
    ]
)


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Helpers communs
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def strip_accents(s: str) -> str:
    return ''.join(c for c in unicodedata.normalize('NFKD', str(s)) if not unicodedata.combining(c))

def norm_col(c: str) -> str:
    c = strip_accents(str(c)).lower().strip()
    c = re.sub(r'[\s\-_\/]+', ' ', c)
    return c

def clean_numeric(x):
    """Convertit vers float en nettoyant espaces/ins√©cables/virgules/texte ; NaN -> 0."""
    if pd.isna(x):
        return 0.0
    s = str(x).strip()
    if s in {"", "-", "NA", "N/A", "na", "n/a", "None", "null"}:
        return 0.0
    s = (s.replace('\u202f', '')
           .replace('\xa0', '')
           .replace(' ', '')
           .replace(',', '.'))
    try:
        return float(s)
    except Exception:
        return 0.0

# Chargement unique du CSV global pour toutes les pages
@st.cache_data
def load_finance_data():
    fname = "Finance_Finale.csv"
    candidates = [
        dict(sep=",", encoding="utf-8"),
        dict(sep=";", encoding="utf-8"),
        dict(sep=",", encoding="utf-8-sig"),
        dict(sep=";", encoding="utf-8-sig"),
        dict(sep=",", encoding="cp1252"),
        dict(sep=";", encoding="cp1252"),
    ]
    last_err = None
    for opt in candidates:
        try:
            df = pd.read_csv(fname, **opt, engine="python")
            if df.shape[1] >= 2:
                return df
        except Exception as e:
            last_err = e
            continue
    raise RuntimeError(f"Impossible de lire {fname} : {last_err}")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# PAGE 1 : INTRODUCTION
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
if page == "Introduction":
    st.image("imaubi.jpeg", use_column_width=True, caption="Ubisoft ‚Äî Franchises et univers embl√©matiques")
    st.title(" üéÆ Ubisoft ‚Äî Introduction")
    
    introduction = """
    Ubisoft est l‚Äôun des plus grands √©diteurs de jeux vid√©o au monde, reconnu pour ses franchises embl√©matiques telles que *Assassin's Creed*, *Far Cry*, *Just Dance*, *Rainbow Six* ou encore *The Division*. Fond√©e en 1986 par les fr√®res Guillemot, l‚Äôentreprise a longtemps incarn√© le savoir-faire vid√©oludique fran√ßais. Introduite en Bourse en 1996, Ubisoft conna√Æt une croissance spectaculaire pendant plus de deux d√©cennies, atteignant un sommet historique en 2018 avec une action valoris√©e √† plus de **100 ‚Ç¨**.

    Depuis ce pic, Ubisoft semble encha√Æner les difficult√©s. En **2024**, sa capitalisation boursi√®re a chut√© de plus de **6 milliards d‚Äôeuros**, une d√©gringolade qui suscite de nombreuses interrogations. Est-elle le reflet d‚Äôune crise sectorielle g√©n√©ralis√©e ? Est-elle symptomatique de difficult√©s internes √† l‚Äôentreprise ?

    √Ä travers ce projet de *data analyse*, notre objectif est de comprendre les facteurs internes ayant contribu√© √† ce d√©clin, en collectant des donn√©es financi√®res, critiques et comportementales. Nous chercherons √©galement √† identifier les signaux faibles et les ruptures strat√©giques pouvant expliquer cette trajectoire descendante, tout en proposant des pistes d‚Äôam√©lioration.
    """
    st.markdown(introduction)
    st.divider()
    
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# PAGE 2 : ANALYSE FINANCI√àRE COMPARATIVE
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
elif page == "Analyse financi√®re comparative":
    st.title(" üìä Analyse Financi√®re Comparative")
    st.caption("√âvolution historique, comparaison avec le secteur et analyse des tendances.")

    try:
        df_finance = load_finance_data()
    except Exception as e:
        st.error(f"‚ö†Ô∏è Chargement CSV √©chou√© : {e}")
        st.stop()

   
    # ‚îÄ‚îÄ PARTIE 1 : Historique Ubisoft (texte + image locale)
    st.markdown("""
    ## 1. Analyse financi√®re comparative  
    ### Une trajectoire spectaculaire puis un effondrement brutal‚Ä¶

    L‚Äôaction **Ubisoft** a connu une √©volution remarquable depuis son introduction en Bourse le **1er juillet 1996**. D√®s le premier jour de cotation, le titre est multipli√© par **252**, port√© par l‚Äôengouement pour l‚Äôindustrie vid√©oludique et une forte lev√©e de fonds.  
    Cette dynamique s‚Äôest poursuivie pendant plus d‚Äôune d√©cennie, atteignant un **pic historique de plus de 100 ‚Ç¨ en juillet 2018**. Cette valorisation exceptionnelle refl√®te alors la solidit√© des franchises d‚ÄôUbisoft, telles que *Assassin‚Äôs Creed*, *Far Cry*, *Rainbow Six Siege* et *The Division*, ainsi que la strat√©gie de l‚Äô√©diteur ax√©e sur les **jeux √† monde ouvert** et √† fort contenu **solo/multijoueur**.  
    Entre **2014 et 2018**, les r√©sultats financiers sont en nette progression, avec un chiffre d‚Äôaffaires passant de **1,4** √† **2,2 milliards de dollars** et une am√©lioration significative des marges. √Ä cette p√©riode, **Tencent** entre au capital, consolidant l‚Äôimage d‚ÄôUbisoft comme acteur strat√©gique √† l‚Äôinternational.  
    Pourtant, d√®s **2019**, les r√©sultats commencent √† d√©cevoir : plusieurs jeux ne r√©pondent pas aux attentes, les retards s‚Äôaccumulent, et la rentabilit√© s‚Äôeffrite. Le titre entame alors une **chute prolong√©e** : en **cinq ans**, l‚Äôaction perd plus de **80 % de sa valeur**. Depuis 2018, cela repr√©sente une **perte de capitalisation boursi√®re d‚Äôenviron 9 milliards d‚Äôeuros**.
    """)

        # ‚îÄ‚îÄ PARTIE 1 : Historique Ubisoft (chargement auto de l'image)
    st.subheader(" √âvolution historique du cours de l‚Äôaction Ubisoft")

    @st.cache_data(show_spinner=False)
    def _find_ubisoft_chart() -> str | None:
        base = Path(__file__).parent
        # chemins les plus probables (mets l'image √† la racine ou dans assets/images/static)
        candidates = [
            base / "ubisoft_google_finance.png",
            base / "assets" / "ubisoft_google_finance.png",
            base / "images" / "ubisoft_google_finance.png",
            base / "static" / "ubisoft_google_finance.png",
            base / "Capture d'√©cran 2025-08-25 141139.png",
            base / "assets" / "Capture d'√©cran 2025-08-25 141139.png",
            base / "images" / "Capture d'√©cran 2025-08-25 141139.png",
            base / "static" / "Capture d'√©cran 2025-08-25 141139.png",
        ]
        for p in candidates:
            if p.exists():
                return str(p)
        # recherche de secours par motif
        for folder in [base, base / "assets", base / "images", base / "static"]:
            for pat in ("ubisoft*finance*.*", "Ubisoft*Finance*.*", "Capture d'√©cran 2025-08-25 141139.*"):
                for p in folder.glob(pat):
                    return str(p)
        return None

    img_path = _find_ubisoft_chart()

    if img_path:
        st.image(
            img_path,
            caption="√âvolution historique du cours Ubisoft ‚Äî Source : Google Finance (EPA : UBI)",
            use_container_width=True
        )
    else:
        st.error(
            "Image introuvable. Place le fichier **ubisoft_google_finance.png** "
            "ou **Capture d'√©cran 2025-08-25 141139.png** √† la racine du projet "
            "ou dans **./assets/**, **./images/** ou **./static/**."
        )

    st.divider()

    # ‚îÄ‚îÄ PARTIE 2 : Performance relative au secteur (texte + courbes comparatives)
    st.markdown("""
    ## 2. Une performance financi√®re en retrait

    Pour mieux comprendre le contexte du d√©clin d‚ÄôUbisoft, nous avons compar√© l‚Äô√©volution de son cours de Bourse √† celle des deux principaux **ETF sectoriels** d√©di√©s au jeu vid√©o : **ESPO** (*VanEck Video Gaming & eSports*) et **HERO** (*Global X Video Games & Esports ETF*). Ces deux indices regroupent les plus grands √©diteurs mondiaux du secteur.

    L‚Äôanalyse sur les **cinq derni√®res ann√©es** met en √©vidence une **divergence nette**. Si les trois courbes suivent une trajectoire globalement similaire jusqu‚Äôen **2022** ‚Äî marqu√©e par une baisse partag√©e ‚Äî, les dynamiques s‚Äôopposent par la suite : **ESPO** repart √† la hausse d√®s **2023**, amor√ßant une phase de croissance continue, tandis qu‚Äô**Ubisoft** poursuit son repli, atteignant m√™me un **point bas autour de 10 ‚Ç¨ en 2024**.

    Cette dissociation entre l‚Äô√©volution du march√© global et celle d‚ÄôUbisoft confirme que **le probl√®me semble sp√©cifique √† l‚Äôentreprise**. La performance boursi√®re d‚ÄôUbisoft ne peut pas √™tre attribu√©e √† une crise sectorielle : au contraire, l‚Äôindustrie du jeu vid√©o **continue de progresser dans son ensemble**. Cela renforce l‚Äôhypoth√®se d‚Äôune **crise interne** ‚Äî un axe que nous tenterons d‚Äôexplorer dans les chapitres suivants.
    """)

    st.subheader(" Comparaison Ubisoft vs ETF ESPO & HERO")
    df_etf = pd.DataFrame({
        "Ann√©e":   [2020, 2021, 2022, 2023, 2024],
        "Ubisoft": [85,   75,   50,   25,   10],
        "ESPO":    [100,  110,  90,   120,  140],
        "HERO":    [95,   105,  85,   115,  135],
    })
    fig2, ax2 = plt.subplots(figsize=(10, 6))
    ax2.plot(df_etf["Ann√©e"], df_etf["Ubisoft"], marker="o", color="red",   label="Ubisoft")
    ax2.plot(df_etf["Ann√©e"], df_etf["ESPO"],    marker="o", color="green", label="ESPO")
    ax2.plot(df_etf["Ann√©e"], df_etf["HERO"],    marker="o", color="blue",  label="HERO")
    ax2.set_title("√âvolution du cours Ubisoft vs ESPO & HERO (5 derni√®res ann√©es)", fontsize=14)
    ax2.set_xlabel("Ann√©e"); ax2.set_ylabel("Valeur normalis√©e (base 100)")
    ax2.grid(True, linestyle="--", alpha=0.6); ax2.legend()
    ax2.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))
    st.pyplot(fig2)
    st.divider()

    # ‚îÄ‚îÄ PARTIE 3 : CA cumul√© par √©diteur (lecture robuste depuis df_finance)
    st.markdown("""
    **Observation compl√©mentaire.**  
    Sur la p√©riode √©tudi√©e, le **chiffre d‚Äôaffaires cumul√©** d‚ÄôUbisoft est **le plus faible parmi les √©diteurs majeurs du secteur**. 
    """)
    st.subheader(" Chiffre d‚Äôaffaires cumul√© par √©diteur (2018‚Äì2024) ")

    raw = df_finance.copy()
    norm_map = {c: norm_col(c) for c in raw.columns}
    df = raw.rename(columns=norm_map)

    cumu_alias = [
        'ca cumule (m‚Ç¨)','ca cumule','chiffre daffaires cumule (m‚Ç¨)',
        'chiffre daffaires cumule','revenue cumule (m‚Ç¨)','revenu cumule (m‚Ç¨)','revenue total (m‚Ç¨)'
    ]
    year_cols_cols = [c for c in df.columns if re.fullmatch(r'(?:fy)?(20(1[8-9]|2[0-4]))', c)]
    if not year_cols_cols:
        year_cols_cols = [c for c in df.columns if re.search(r'20(1[8-9]|2[0-4])', c)]
    year_line_alias = ['annee','year','date']
    editor_alias = ['editeur','√©diteur','publisher','societe','entreprise','company','studio','nom','compagnie']
    editor_col = next((c for c in df.columns if c in editor_alias), None)
    if editor_col is None:
        for c in df.columns:
            if df[c].dtype == object:
                editor_col = c; break
    if editor_col is None:
        st.error("Colonne 'Editeur' introuvable dans Finance_Finale.csv"); st.stop()

    cumu_col = next((c for c in df.columns if c in cumu_alias), None)
    if cumu_col:
        out = pd.DataFrame({
            "√âditeur": df[editor_col],
            "CA cumul√© (M‚Ç¨)": df[cumu_col].apply(clean_numeric)
        })
    elif year_cols_cols:
        tmp = df[[editor_col] + year_cols_cols].copy()
        for c in year_cols_cols:
            tmp[c] = tmp[c].apply(clean_numeric)
        total = tmp[year_cols_cols].sum(axis=1)
        if pd.notna(total.max()) and total.max() > 1_000_000:
            total = total / 1_000_000.0
        out = pd.DataFrame({"√âditeur": tmp[editor_col], "CA cumul√© (M‚Ç¨)": total})
    else:
        annee_col = next((c for c in df.columns if c in year_line_alias or "annee" in c or "year" in c or "date" in c), None)
        ca_candidates = [c for c in df.columns if any(k in c for k in ['chiffre','revenue','revenu','sales','ca '])]
        ca_col = ca_candidates[0] if ca_candidates else None
        if not (annee_col and ca_col):
            st.error("Colonnes n√©cessaires non trouv√©es (Ann√©e + Chiffre d'affaires)."); st.stop()
        work = df[[editor_col, annee_col, ca_col]].copy()
        work['__year__'] = pd.to_datetime(work[annee_col], errors='coerce').dt.year
        work['__ca__'] = work[ca_col].apply(clean_numeric)
        mask = work['__year__'].between(2018, 2024, inclusive='both')
        grouped = (work[mask].groupby(editor_col, as_index=False)['__ca__'].sum()
                   .rename(columns={editor_col:"√âditeur", '__ca__':"CA cumul√© (M‚Ç¨)"}))
        out = grouped
        if pd.notna(out["CA cumul√© (M‚Ç¨)"].max()) and out["CA cumul√© (M‚Ç¨)"].max() > 1_000_000:
            out["CA cumul√© (M‚Ç¨)"] = out["CA cumul√© (M‚Ç¨)"] / 1_000_000.0

    out = out.dropna(subset=["√âditeur"]).copy()
    out["CA cumul√© (M‚Ç¨)"] = pd.to_numeric(out["CA cumul√© (M‚Ç¨)"], errors='coerce').fillna(0)
    out = out.sort_values("CA cumul√© (M‚Ç¨)", ascending=False)

    fig3, ax3 = plt.subplots(figsize=(10, 6))
    bars = ax3.bar(out["√âditeur"], out["CA cumul√© (M‚Ç¨)"])
    ax3.set_title("Chiffre d'affaires cumul√© par √©diteur de 2018 √† 2024", fontsize=14)
    ax3.set_xlabel("√âditeurs"); ax3.set_ylabel("Chiffre d'affaires cumul√© (M‚Ç¨)")
    ax3.grid(axis="y", linestyle="--", alpha=0.5)
    plt.xticks(rotation=45, ha="right")
    for b, v in zip(bars, out["CA cumul√© (M‚Ç¨)"]):
        ax3.annotate(f"{int(round(v)):,}".replace(",", " "),
                     xy=(b.get_x() + b.get_width()/2, v),
                     xytext=(0, 5), textcoords="offset points",
                     ha="center", va="bottom", fontsize=9)
    st.pyplot(fig3)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Graphiques comparatifs CA, R√©sultat net, Masse salariale (interactifs)
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.divider()
    st.markdown("""
    Plus pr√©occupant encore, **le chiffre d‚Äôaffaires d‚ÄôUbisoft n‚Äô√©volue quasiment pas**, alors que la majorit√© des **concurrents** (*Sony Interactive Entertainment, Electronic Arts, Bandai Namco*, etc.) affichent **une croissance continue**.  
    Cette **stagnation** est un **signal d‚Äôalerte fort**, d‚Äôautant plus que le **march√© global du jeu vid√©o** est, lui, **en croissance**.
    """)
    st.subheader("√âvolution du chiffre d‚Äôaffaires (2018‚Äì2024) ")

    def _to_long(df_in: pd.DataFrame) -> pd.DataFrame:
        df = df_in.rename(columns={c: unicodedata.normalize("NFKD", str(c)).encode("ascii","ignore").decode().strip().lower()
                                   for c in df_in.columns})
        year_cols = [c for c in df.columns if re.fullmatch(r'(?:fy)?(20(1[8-9]|2[0-4]))', c)]
        if not year_cols:
            year_cols = [c for c in df.columns if re.search(r'20(1[8-9]|2[0-4])', c)]
        ed_col = next((c for c in df.columns if c in
                       ["editeur","publisher","entreprise","societe","company","studio","nom","compagnie"]), None)
        if ed_col is None:
            for c in df.columns:
                if df[c].dtype == object:
                    ed_col = c; break
        if ed_col is None:
            raise ValueError("Colonne √©diteur introuvable.")

        if year_cols:
            long = df[[ed_col] + year_cols].copy().melt(id_vars=[ed_col], var_name="annee", value_name="valeur")
            long["annee"] = long["annee"].astype(str).str.extract(r'(20\d{2})').astype(int)
            long["valeur"] = long["valeur"].apply(clean_numeric)
            long = long.rename(columns={ed_col:"Editeur"})
            return long

        an_col = next((c for c in df.columns if c in ["annee","year","date"] or "annee" in c or "year" in c or "date" in c), None)
        val_col = next((c for c in df.columns if any(k in c for k in ["chiffre","revenue","revenu","sales","ca"])), None)
        if an_col is None or val_col is None:
            raise ValueError("Colonnes requises non trouv√©es (Ann√©e + CA).")
        long = df[[ed_col, an_col, val_col]].copy().rename(columns={ed_col:"Editeur", an_col:"annee", val_col:"valeur"})
        long["annee"] = pd.to_datetime(long["annee"], errors="coerce").dt.year
        long["valeur"] = long["valeur"].apply(clean_numeric)
        return long

    df_multi_raw = df_finance.copy()
    data_long = _to_long(df_multi_raw)
    data_long = data_long.dropna(subset=["Editeur","annee"])
    data_long = data_long[(data_long["annee"]>=2018) & (data_long["annee"]<=2024)]
    data_long["valeur"] = data_long["valeur"].apply(clean_numeric)

    editeurs_dispos = sorted(data_long["Editeur"].unique().tolist())
    col_a, col_b = st.columns([2,1])
    with col_a:
        sel_editeurs = st.multiselect("√âditeurs √† afficher :", editeurs_dispos, default=editeurs_dispos)
    with col_b:
        years_min, years_max = int(data_long["annee"].min()), int(data_long["annee"].max())
        an_range = st.slider("Plage d‚Äôann√©es :", min_value=years_min, max_value=years_max, value=(2018, 2024), step=1)

    dfp = data_long[(data_long["Editeur"].isin(sel_editeurs)) &
                    (data_long["annee"].between(an_range[0], an_range[1]))].copy()
    full_index = pd.MultiIndex.from_product([sorted(set(sel_editeurs)), list(range(an_range[0], an_range[1]+1))],
                                            names=["Editeur", "annee"])
    dfp = (dfp.groupby(["Editeur", "annee"], as_index=False)["valeur"].sum()
              .set_index(["Editeur","annee"])
              .reindex(full_index)
              .fillna(0.0)
              .reset_index())

    if dfp.empty:
        st.warning("Aucune donn√©e pour la s√©lection actuelle.")
    else:
        annees = sorted(dfp["annee"].unique().tolist())
        publishers = sel_editeurs
        n_pub = len(publishers)
        total_width = 0.8
        bar_width = total_width / max(n_pub,1)
        x = list(range(len(annees)))
        fig, ax = plt.subplots(figsize=(10,6))
        for i, pub in enumerate(publishers):
            y_vals = [float(dfp[(dfp["Editeur"]==pub) & (dfp["annee"]==a)]["valeur"].sum()) for a in annees]
            offsets = [xx + (i - (n_pub-1)/2)*bar_width for xx in x]
            ax.bar(offsets, y_vals, width=bar_width, label=pub)
        ax.set_xticks(x); ax.set_xticklabels(annees, rotation=0)
        ax.set_title("√âvolution du chiffre d‚Äôaffaires (M‚Ç¨) par √©diteur", fontsize=14)
        ax.set_xlabel("Ann√©e"); ax.set_ylabel("Chiffre d'affaires (M‚Ç¨)")
        ax.grid(axis="y", linestyle="--", alpha=0.5)
        ax.legend(ncol=2, fontsize=9)
        st.pyplot(fig)

    # R√©sultat net ‚Äî similaire
    st.divider()
    st.markdown("""
    **Le r√©sultat net cumul√© d‚ÄôUbisoft est en net retrait par rapport √† ses pairs**, alors que la majorit√© de ses concurrents restent **b√©n√©ficiaires** sur la m√™me p√©riode.  
    Ce **d√©ficit chronique** montre qu‚ÄôUbisoft ne parvient pas √† **transformer ses ventes en valeur** pour ses actionnaires, et que sa **structure de co√ªts** n‚Äôest pas suffisamment ma√Ætris√©e.
    """)
    st.subheader(" R√©sultat net (M‚Ç¨) ‚Äî √©volution 2018‚Äì2024")

    def to_long_metric(df_in: pd.DataFrame, metric_keywords) -> pd.DataFrame:
        df = df_in.rename(columns={c: norm_col(c) for c in df_in.columns})
        year_cols = [c for c in df.columns if re.fullmatch(r'(?:fy)?(20(1[8-9]|2[0-4]))', c)]
        if not year_cols:
            year_cols = [c for c in df.columns if re.search(r'20(1[8-9]|2[0-4])', c)]
        ed_col = next((c for c in df.columns if c in
                       ["editeur","√©diteur","publisher","entreprise","societe","company","studio","nom","compagnie"]), None)
        if ed_col is None:
            for c in df.columns:
                if df[c].dtype == object:
                    ed_col = c; break
        if ed_col is None:
            raise ValueError("Colonne √©diteur introuvable.")
        if year_cols:
            long = df[[ed_col] + year_cols].copy().melt(id_vars=[ed_col], var_name="annee", value_name="valeur")
            long["annee"] = long["annee"].astype(str).str.extract(r'(20\d{2})').astype(int)
            long["valeur"] = long["valeur"].apply(clean_numeric)
            long = long.rename(columns={ed_col: "Editeur"})
            return long
        an_col = next((c for c in df.columns if c in ["annee","year","date"] or "annee" in c or "year" in c or "date" in c), None)
        val_col = next((c for c in df.columns if any(k in c for k in metric_keywords)), None)
        if an_col is None or val_col is None:
            raise ValueError("Colonnes requises non trouv√©es (Ann√©e + R√©sultat net).")
        long = df[[ed_col, an_col, val_col]].copy().rename(columns={ed_col:"Editeur", an_col:"annee", val_col:"valeur"})
        long["annee"] = pd.to_datetime(long["annee"], errors="coerce").dt.year
        long["valeur"] = long["valeur"].apply(clean_numeric)
        return long

    data_profit = to_long_metric(df_finance.copy(), ["resultat","r√©sultat","net income","profit","benefice","b√©n√©fice"])
    data_profit = data_profit.dropna(subset=["Editeur","annee"])
    data_profit = data_profit[(data_profit["annee"]>=2018) & (data_profit["annee"]<=2024)]
    data_profit["valeur"] = data_profit["valeur"].apply(clean_numeric)

    editeurs_p = sorted(data_profit["Editeur"].unique().tolist())
    col1, col2 = st.columns([2,1])
    with col1:
        sel_ed_p = st.multiselect("√âditeurs √† afficher :", editeurs_p, default=editeurs_p, key="prof_ed")
    with col2:
        y_min, y_max = int(data_profit["annee"].min()), int(data_profit["annee"].max())
        an_range_p = st.slider("Plage d‚Äôann√©es :", min_value=y_min, max_value=y_max, value=(2018, 2024), step=1, key="prof_year")

    dfp_p = data_profit[(data_profit["Editeur"].isin(sel_ed_p)) &
                        (data_profit["annee"].between(an_range_p[0], an_range_p[1]))].copy()
    idx_full = pd.MultiIndex.from_product([sorted(set(sel_ed_p)), list(range(an_range_p[0], an_range_p[1]+1))],
                                          names=["Editeur","annee"])
    dfp_p = (dfp_p.groupby(["Editeur","annee"], as_index=False)["valeur"].sum()
                .set_index(["Editeur","annee"])
                .reindex(idx_full)
                .fillna(0.0)
                .reset_index())

    if dfp_p.empty:
        st.warning("Aucune donn√©e pour la s√©lection actuelle.")
    else:
        annees_p = sorted(dfp_p["annee"].unique().tolist())
        pubs_p = sel_ed_p; n_pub_p = len(pubs_p)
        total_w = 0.8; bw = total_w / max(n_pub_p,1); x = list(range(len(annees_p)))
        figp, axp = plt.subplots(figsize=(10,6))
        for i, pub in enumerate(pubs_p):
            yv = [float(dfp_p[(dfp_p["Editeur"]==pub) & (dfp_p["annee"]==a)]["valeur"].sum()) for a in annees_p]
            offs = [xx + (i - (n_pub_p-1)/2)*bw for xx in x]
            axp.bar(offs, yv, width=bw, label=pub)
        axp.axhline(0, color="black", linewidth=1)
        axp.set_xticks(x); axp.set_xticklabels(annees_p, rotation=0)
        axp.set_title("R√©sultat net (M‚Ç¨) par √©diteur", fontsize=14)
        axp.set_xlabel("Ann√©e"); axp.set_ylabel("R√©sultat net (M‚Ç¨)")
        axp.grid(axis="y", linestyle="--", alpha=0.5)
        axp.legend(ncol=2, fontsize=9)
        st.pyplot(figp)

    # Masse salariale
    st.divider()
    st.markdown("""
    L‚Äôun des √©carts les plus marquants est observ√© au niveau de la **masse salariale**.  
    **Ubisoft** emploie un volume de salari√©s **comparable** √† celui d‚Äô**Activision Blizzard**, mais ses **performances financi√®res** sont nettement **inf√©rieures**.  
    Par exemple, **Electronic Arts** op√®re avec **environ un tiers de personnel en moins**, tout en g√©n√©rant un **chiffre d‚Äôaffaires** et un **r√©sultat net** largement sup√©rieurs.
    """)
    st.subheader(" Masse salariale (M‚Ç¨) ‚Äî √©volution 2018‚Äì2024")

    def _to_long_payroll(df_in: pd.DataFrame) -> pd.DataFrame:
        df = df_in.rename(columns={c: norm_col(c) for c in df_in.columns})
        year_cols = [c for c in df.columns if re.fullmatch(r'(?:fy)?(20(1[8-9]|2[0-4]))', c)]
        if not year_cols:
            year_cols = [c for c in df.columns if re.search(r'20(1[8-9]|2[0-4])', c)]
        ed_col = next((c for c in df.columns if c in
                      ["editeur","√©diteur","publisher","entreprise","societe","company","studio","nom","compagnie"]), None)
        if ed_col is None:
            for c in df.columns:
                if df[c].dtype == object:
                    ed_col = c; break
        if ed_col is None:
            raise ValueError("Colonne √©diteur introuvable.")
        if year_cols:
            long = df[[ed_col] + year_cols].copy().melt(id_vars=[ed_col], var_name="annee", value_name="valeur")
            long["annee"] = long["annee"].astype(str).str.extract(r'(20\d{2})').astype(int)
            long["valeur"] = long["valeur"].apply(clean_numeric)
            long = long.rename(columns={ed_col:"Editeur"})
            return long
        an_col = next((c for c in df.columns if c in ["annee","year","date"] or "annee" in c or "year" in c or "date" in c), None)
        val_col = next((c for c in df.columns if any(k in c for k in
                   ["masse salariale","payroll","personnel","staff cost","wages","salaires","salary","co√ªt du personnel","cout du personnel"])), None)
        if an_col is None or val_col is None:
            raise ValueError("Colonnes requises non trouv√©es (Ann√©e + Masse salariale).")
        long = df[[ed_col, an_col, val_col]].copy().rename(columns={ed_col:"Editeur", an_col:"annee", val_col:"valeur"})
        long["annee"] = pd.to_datetime(long["annee"], errors="coerce").dt.year
        long["valeur"] = long["valeur"].apply(clean_numeric)
        return long

    payroll_long = _to_long_payroll(df_finance.copy())
    payroll_long = payroll_long.dropna(subset=["Editeur","annee"])
    payroll_long = payroll_long[(payroll_long["annee"]>=2018) & (payroll_long["annee"]<=2024)]
    payroll_long["valeur"] = payroll_long["valeur"].apply(clean_numeric)

    editeurs_pay = sorted(payroll_long["Editeur"].unique().tolist())
    c1, c2 = st.columns([2,1])
    with c1:
        sel_editeurs_pay = st.multiselect("√âditeurs √† afficher :", editeurs_pay, default=editeurs_pay, key="pay_ed")
    with c2:
        y_min_p, y_max_p = int(payroll_long["annee"].min()), int(payroll_long["annee"].max())
        an_range_pay = st.slider("Plage d‚Äôann√©es :", min_value=y_min_p, max_value=y_max_p, value=(2018, 2024), step=1, key="pay_year")

    dfp_pay = payroll_long[(payroll_long["Editeur"].isin(sel_editeurs_pay)) &
                           (payroll_long["annee"].between(an_range_pay[0], an_range_pay[1]))].copy()
    full_idx_pay = pd.MultiIndex.from_product([sorted(set(sel_editeurs_pay)),
                                               list(range(an_range_pay[0], an_range_pay[1]+1))],
                                              names=["Editeur","annee"])
    dfp_pay = (dfp_pay.groupby(["Editeur","annee"], as_index=False)["valeur"].sum()
                    .set_index(["Editeur","annee"])
                    .reindex(full_idx_pay)
                    .fillna(0.0)
                    .reset_index())

    if dfp_pay.empty:
        st.warning("Aucune donn√©e pour la s√©lection actuelle (masse salariale).")
    else:
        annees_pay = sorted(dfp_pay["annee"].unique().tolist())
        pubs_pay = sel_editeurs_pay
        n_pub_pay = len(pubs_pay)
        total_w = 0.8; bw = total_w / max(n_pub_pay,1); x = list(range(len(annees_pay)))
        figp2, axp2 = plt.subplots(figsize=(10,6))
        for i, pub in enumerate(pubs_pay):
            y_vals = [float(dfp_pay[(dfp_pay["Editeur"]==pub) & (dfp_pay["annee"]==a)]["valeur"].sum()) for a in annees_pay]
            offs = [xx + (i - (n_pub_pay-1)/2)*bw for xx in x]
            axp2.bar(offs, y_vals, width=bw, label=pub)
        axp2.set_xticks(x); axp2.set_xticklabels(annees_pay, rotation=0)
        axp2.set_title("√âvolution de la masse salariale (M‚Ç¨) par √©diteur", fontsize=14)
        axp2.set_xlabel("Ann√©e"); axp2.set_ylabel("Masse salariale (M‚Ç¨)")
        axp2.grid(axis="y", linestyle="--", alpha=0.5)
        axp2.legend(ncol=2, fontsize=9)
        st.pyplot(figp2)

    # Bulles : CA‚ÜîR√©sultat (taille = masse salariale) + Masse salariale ‚Üî Effectif
    st.divider()
    st.subheader(" R√©sultat net vs Chiffre d‚Äôaffaires ")
    st.caption("Les deux graphiques ci-dessous utilisent les m√™mes donn√©es centralis√©es.")

    def _normalize_columns_for_panel(df_in: pd.DataFrame) -> pd.DataFrame:
        df = df_in.rename(columns={c: norm_col(c) for c in df_in.columns})
        ed_col = next((c for c in df.columns if c in
                       ["editeur","√©diteur","publisher","entreprise","societe","company","studio","nom","compagnie"]), None)
        if ed_col is None:
            for c in df.columns:
                if df[c].dtype == object:
                    ed_col = c; break
        if ed_col is None:
            raise ValueError("Colonne √©diteur introuvable.")
        KEYWORDS = {
            "ca": ["chiffre","sales","revenue","revenu","ca"],
            "profit": ["resultat","r√©sultat","net income","profit","benefice","b√©n√©fice"],
            "payroll": ["masse salariale","payroll","personnel","staff cost","wages","salaires","salary","co√ªt du personnel","cout du personnel"],
            "headcount": ["effectif","headcount","employe","employee","staff"]
        }
        def find_col(dfcols, words):
            return next((c for c in dfcols if any(w in c for w in words)), None)

        an_col = next((c for c in df.columns if c in ["annee","year","date"] or "annee" in c or "year" in c or "date" in c), None)
        ca_col      = find_col(df.columns, KEYWORDS["ca"])
        profit_col  = find_col(df.columns, KEYWORDS["profit"])
        payroll_col = find_col(df.columns, KEYWORDS["payroll"])
        headc_col   = find_col(df.columns, KEYWORDS["headcount"])

        panel = pd.DataFrame({"Editeur": df[ed_col]})
        if an_col is not None:
            panel["annee"] = pd.to_datetime(df[an_col], errors="coerce").dt.year
        else:
            panel["annee"] = np.nan

        if ca_col:      panel["ca"]       = df[ca_col].apply(clean_numeric)
        if profit_col:  panel["profit"]   = df[profit_col].apply(clean_numeric)
        if payroll_col: panel["payroll"]  = df[payroll_col].apply(clean_numeric)
        if headc_col:   panel["headcount"]= df[headc_col].apply(clean_numeric)
        for col in ["ca","profit","payroll","headcount"]:
            if col not in panel.columns:
                panel[col] = 0.0
        return panel

    panel = _normalize_columns_for_panel(df_finance.copy())
    panel = panel.dropna(subset=["Editeur"])
    if panel["annee"].notna().any():
        panel = panel[(panel["annee"].between(2018, 2024, inclusive="both")) | panel["annee"].isna()].copy()
    for c in ["ca","profit","payroll","headcount"]:
        panel[c] = panel[c].apply(clean_numeric)

    colsA, colsB, colsC = st.columns([2,1,1])
    with colsA:
        editeurs_sel = st.multiselect("√âditeurs :", sorted(panel["Editeur"].unique()),
                                      default=sorted(panel["Editeur"].unique()))
    with colsB:
        if panel["annee"].notna().any():
            y_min2, y_max2 = int(panel["annee"].min()), int(panel["annee"].max())
            an_range2 = st.slider("Ann√©es :", min_value=y_min2, max_value=y_max2, value=(max(2018,y_min2), min(2024,y_max2)), step=1)
        else:
            an_range2 = (2018, 2024)
    with colsC:
        size_scale = st.slider("√âchelle des bulles (masse salariale)", 0.1, 2.0, 0.7, 0.1)
        alpha_pts  = st.slider("Transparence", 0.2, 1.0, 0.8, 0.1)

    if panel["annee"].notna().any():
        dfp_panel = panel[(panel["Editeur"].isin(editeurs_sel)) &
                          (panel["annee"].between(an_range2[0], an_range2[1]))].copy()
    else:
        dfp_panel = panel[panel["Editeur"].isin(editeurs_sel)].copy()

    if dfp_panel.empty:
        st.warning("Aucune donn√©e pour la s√©lection actuelle.")
    else:
        fig_b, ax_b = plt.subplots(figsize=(9.5, 6.5))
        for ed in sorted(dfp_panel["Editeur"].unique()):
            d = dfp_panel[dfp_panel["Editeur"] == ed]
            ax_b.scatter(d["ca"], d["profit"], s=np.sqrt(d["payroll"].clip(lower=0))*(10*size_scale),
                         alpha=alpha_pts, label=ed)
        ax_b.set_title("R√©sultat net (M‚Ç¨) en fonction du chiffre d‚Äôaffaires (M‚Ç¨) ‚Äî taille = masse salariale", fontsize=13)
        ax_b.set_xlabel("Chiffre d‚Äôaffaires (M‚Ç¨)")
        ax_b.set_ylabel("R√©sultat net (M‚Ç¨)")
        ax_b.grid(True, linestyle="--", alpha=0.4)
        ax_b.legend(ncol=2, fontsize=9, frameon=True)
        st.pyplot(fig_b)

        st.subheader(" Masse salariale vs Effectif total (2018‚Äì2024)")
        fig_c, ax_c = plt.subplots(figsize=(9.5, 6.0))
        for ed in sorted(dfp_panel["Editeur"].unique()):
            d = dfp_panel[dfp_panel["Editeur"] == ed]
            ax_c.scatter(d["headcount"], d["payroll"], alpha=alpha_pts, label=ed)
        ax_c.set_title("Co√ªt de la masse salariale (M‚Ç¨) en fonction de l‚Äôeffectif total", fontsize=13)
        ax_c.set_xlabel("Effectif total (personnes)")
        ax_c.set_ylabel("Masse salariale (M‚Ç¨)")
        ax_c.grid(True, linestyle="--", alpha=0.4)
        ax_c.legend(ncol=2, fontsize=9, frameon=True)
        st.pyplot(fig_c)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# PAGE 3 : ANALYSE DES PERFORMANCES DES JEUX UBISOFT
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
elif page == "Analyse des performances des jeux Ubisoft":
    st.title("üéØ Analyse des performances des jeux Ubisoft")
    st.markdown("""
    Au-del√† des indicateurs financiers globaux, l‚Äôanalyse du **catalogue** d‚ÄôUbisoft r√©v√®le des √©l√©ments structurants.
    En √©tudiant la fr√©quence des sorties, les revenus par jeu et le volume total de titres publi√©s, on observe des tendances claires.
    """)

    st.subheader("2.1. Une strat√©gie ax√©e sur le volume")
    st.markdown("""
    Ubisoft se distingue de ses concurrents par une production particuli√®rement **prolifique** :
    le **nombre de jeux publi√©s** chaque ann√©e est largement sup√©rieur √† la moyenne du secteur.
    Cette strat√©gie s‚Äôappuie sur une **capacit√© de d√©veloppement r√©partie** sur plusieurs studios dans le monde,
    ainsi que sur des **processus industriels bien rod√©s**.
    """)

    # ---------- IMPORTS ----------
    import pandas as pd
    import plotly.express as px
    import plotly.graph_objects as go
    import unicodedata, re

    # ---------- Helpers ----------
    def _norm(s: str) -> str:
        s = unicodedata.normalize("NFKD", str(s))
        s = "".join(c for c in s if not unicodedata.combining(c))
        return re.sub(r"[\s\-_\/]+", " ", s).strip().lower()

    def _to_float(x):
        if pd.isna(x): return 0.0
        s = (str(x).strip()
                .replace("\u202f","").replace("\xa0","")
                .replace(" ", "").replace(",", "."))
        s = re.sub(r"(‚Ç¨|eur|euros|millions?)$", "", s, flags=re.I)
        try: return float(s)
        except: return 0.0

    def apply_light_theme(fig, *, title_text, x_title, y1_title, y2_title=None):
        layout_kwargs = dict(
            title=dict(text=title_text, x=0.5, xanchor="center",
                       font=dict(size=20, color="#000")),
            plot_bgcolor="white",
            paper_bgcolor="white",
            hovermode="x unified",
            legend=dict(bgcolor="rgba(255,255,255,0.9)", bordercolor="#000", borderwidth=1, font=dict(size=13, color="#111")),
            margin=dict(l=70, r=70, t=70, b=70),
            xaxis=dict(title=x_title, tickfont=dict(size=12, color="#000"),
                       showline=True, linecolor="#000", linewidth=2, showgrid=True, gridcolor="rgba(0,0,0,0.25)"),
            yaxis=dict(title=y1_title, tickfont=dict(size=12, color="#000"),
                       showline=True, linecolor="#000", linewidth=2, showgrid=True, gridcolor="rgba(0,0,0,0.25)"),
            height=460
        )
        if y2_title:
            layout_kwargs["yaxis2"] = dict(
                title=y2_title, overlaying="y", side="right",
                showline=True, linecolor="#000", linewidth=2,
                tickfont=dict(size=12, color="#000")
            )
        fig.update_layout(**layout_kwargs)
        return fig

    def _find_col(dfcols, keywords):
        for c in dfcols:
            if any(k in c for k in keywords):
                return c
        return None

    # ---------- Chargement du CSV √©diteurs ----------
    try:
        df_ed = pd.read_csv("editeurs_nettoy√©es.csv")
    except Exception as e:
        st.error(f"‚ö†Ô∏è Impossible de charger le CSV : {e}")
        st.stop()

    # ---------- V√©rification/alignement colonnes ----------
    expected_cols = ["Nom", "Jeux publi√©s", "Revenu total (milliards)"]
    for col in expected_cols:
        if col not in df_ed.columns:
            cands = [c for c in df_ed.columns if _norm(c) == _norm(col)]
            if cands:
                df_ed.rename(columns={cands[0]: col}, inplace=True)
            else:
                st.error(f"‚ö†Ô∏è Colonne manquante : '{col}' ‚Äî colonnes disponibles : {list(df_ed.columns)}")
                st.stop()

    # ---------- Harmonisation des √©diteurs ----------
    mapping_editeurs = {
        "ubisoft": "Ubisoft",
        "electronic arts": "Electronic Arts", "ea": "Electronic Arts",
        "sega": "SEGA",
        "square enix": "Square Enix",
        "bandai": "Bandai Namco", "bandai namco": "Bandai Namco",
        "take two": "Take-Two", "take-two": "Take-Two", "2k": "Take-Two", "2k games": "Take-Two"
    }
    df_ed["Editeur"] = df_ed["Nom"].apply(lambda x: mapping_editeurs.get(_norm(x), None))

    # ---------- Filtrer les 6 √©diteurs du projet ----------
    editeurs_cibles = ["Ubisoft", "Electronic Arts", "SEGA", "Square Enix", "Bandai Namco", "Take-Two"]
    dff = df_ed[df_ed["Editeur"].isin(editeurs_cibles)].copy()
    if dff.empty:
        st.error("‚ö†Ô∏è Aucune donn√©e trouv√©e pour les 6 √©diteurs attendus.")
        st.write("√âditeurs trouv√©s :", sorted(df_ed["Nom"].unique()))
        st.stop()

    # ---------- Agr√©gation ----------
    dff = (dff.groupby("Editeur", as_index=False)
              .agg(**{
                  "Jeux publi√©s": ("Jeux publi√©s", "sum"),
                  "Revenu total (milliards)": ("Revenu total (milliards)", "sum")
              }))

    # ---------- Graphique 1 : Volume vs Revenu total ----------
    dff["Couleur"] = dff["Editeur"].apply(lambda n: "Ubisoft" if n == "Ubisoft" else "Autres")
    fig1 = px.scatter(
        dff,
        x="Jeux publi√©s",
        y="Revenu total (milliards)",
        text="Editeur",
        color="Couleur",
        color_discrete_map={"Ubisoft": "#e53935", "Autres": "#6e6e6e"},
        size=[26] * len(dff),
        size_max=28,
        labels={
            "Jeux publi√©s": "Nombre de jeux publi√©s (somme 2018‚Äì2024)",
            "Revenu total (milliards)": "Revenu total (en milliards d'‚Ç¨)"
        }
    )
    fig1.update_layout(
        showlegend=False,
        plot_bgcolor="white",
        paper_bgcolor="white",
        font=dict(color="black", size=14),
        title=dict(
            text="Relation entre le nombre de jeux publi√©s et le revenu total",
            font=dict(size=18, color="black"),
            x=0.5, xanchor="center"
        ),
        margin=dict(l=100, r=60, t=60, b=70),
    )
    fig1.update_xaxes(showgrid=True, gridcolor="#CCCCCC", zeroline=False,
                      automargin=True, title_font=dict(size=16, color="black"),
                      tickfont=dict(size=14, color="black"))
    fig1.update_yaxes(showgrid=True, gridcolor="#CCCCCC", zeroline=False,
                      automargin=True, title_standoff=22,
                      title_font=dict(size=16, color="black"),
                      tickfont=dict(size=14, color="black"))

    # Padding dynamique
    x_min, x_max = dff["Jeux publi√©s"].min(), dff["Jeux publi√©s"].max()
    y_min, y_max = dff["Revenu total (milliards)"].min(), dff["Revenu total (milliards)"].max()
    dx = max(6, (x_max - x_min) * 0.08)
    dy = max(0.4, (y_max - y_min) * 0.10)
    fig1.update_xaxes(range=[x_min - dx, x_max + dx])
    fig1.update_yaxes(range=[max(0, y_min - dy), y_max + dy])
    fig1.update_traces(textposition="top center", cliponaxis=False)

    st.plotly_chart(fig1, use_container_width=True)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # 2.2 ‚Äî Relation volume de jeux / revenu moyen par jeu
    # + Titre demand√© "D√©pendance aux Blogs Busters" (sans cr√©er de section)
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    

    st.markdown("""
    Cependant, cette approche atteint ses **limites**. En effet, le **revenu moyen g√©n√©r√© par jeu** reste inf√©rieur √† celui de concurrents
    comme **Electronic Arts** ou **Take-Two**, qui publient moins de titres mais maximisent la **rentabilit√©** de chacun.
    """)

    if "Revenu moyen par jeu (M‚Ç¨)" not in dff.columns:
        dff["Revenu moyen par jeu (M‚Ç¨)"] = (dff["Revenu total (milliards)"] * 1000.0) / dff["Jeux publi√©s"]

    fig2 = px.scatter(
        dff,
        x="Jeux publi√©s",
        y="Revenu moyen par jeu (M‚Ç¨)",
        text="Editeur",
        color="Couleur",
        color_discrete_map={"Ubisoft": "#e53935", "Autres": "#6e6e6e"},
        size=[26] * len(dff),
        size_max=28,
        labels={"Jeux publi√©s": "Jeux publi√©s", "Revenu moyen par jeu (M‚Ç¨)": "Revenu moyen par jeu (M‚Ç¨)"}
    )
    fig2.update_layout(
        showlegend=False,
        plot_bgcolor="white",
        paper_bgcolor="white",
        font=dict(color="black", size=14),
        title=dict(
            text="Relation volume de jeux / Revenu moyen par jeu (Ubisoft vs concurrents)",
            font=dict(size=18, color="black"),
            x=0.5, xanchor="center"
        ),
        margin=dict(l=100, r=60, t=70, b=70),
    )
    fig2.update_xaxes(showgrid=True, gridcolor="#CCCCCC", zeroline=False,
                      automargin=True, title_font=dict(size=16, color="black"),
                      tickfont=dict(size=14, color="black"))
    fig2.update_yaxes(showgrid=True, gridcolor="#CCCCCC", zeroline=False,
                      automargin=True, title_standoff=22,
                      title_font=dict(size=16, color="black"),
                      tickfont=dict(size=14, color="black"))

    # Padding dynamique
    x2_min, x2_max = dff["Jeux publi√©s"].min(), dff["Jeux publi√©s"].max()
    y2_min, y2_max = dff["Revenu moyen par jeu (M‚Ç¨)"].min(), dff["Revenu moyen par jeu (M‚Ç¨)"].max()
    dx2 = max(8, (x2_max - x2_min) * 0.10)
    dy2 = max(10, (y2_max - y2_min) * 0.12)
    fig2.update_xaxes(range=[x2_min - dx2, x2_max + dx2])
    fig2.update_yaxes(range=[max(0, y2_min - dy2), y2_max + dy2])
    fig2.update_traces(textposition="top center", cliponaxis=False)

    st.plotly_chart(fig2, use_container_width=True)

    st.markdown("""
    Le **choix de miser sur la quantit√©** plut√¥t que sur la **rentabilit√© par titre** semble diluer l'impact de chaque sortie,
    et affaiblit la capacit√© de l'√©diteur √† transformer ses lancements en **succ√®s retentissants**.
    """)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # S√©ries annuelles : Revenus & Unit√©s vendues ‚Äî textes AVANT/APR√àS identiques au doc
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Chargement donn√©es jeux d√©taill√©es
    @st.cache_data
    def _load_jeux_csv():
        fname = "Jeux_final.csv"
        tries = [
            dict(sep=",", encoding="utf-8"),
            dict(sep=";", encoding="utf-8"),
            dict(sep=",", encoding="utf-8-sig"),
            dict(sep=";", encoding="utf-8-sig"),
            dict(sep="\t", encoding="utf-8"),
            dict(sep=",", encoding="cp1252"),
            dict(sep=";", encoding="cp1252"),
        ]
        last = None
        for opt in tries:
            try:
                df = pd.read_csv(fname, engine="python", **opt)
                if df.shape[1] >= 2:
                    return df
            except Exception as e:
                last = e
        raise RuntimeError(f"Impossible de lire {fname} : {last}")

    try:
        dfj_raw = _load_jeux_csv()
    except Exception as e:
        st.error(f"‚ö†Ô∏è Chargement de `Jeux_final.csv` impossible : {e}")
        st.stop()

    dfj = dfj_raw.copy()
    dfj.columns = [_norm(c) for c in dfj.columns]

    col_date   = _find_col(dfj.columns, ["premiere publication", "publication", "release", "date"])
    col_rev    = _find_col(dfj.columns, ["revenus", "sales", "chiffre d", "ca"])
    col_units  = _find_col(dfj.columns, ["unites", "unit√©s", "units", "copies", "ventes"])
    col_medhrs = _find_col(dfj.columns, ["temps median", "temps m√©dian", "median playtime", "temps de jeu"])

    if not (col_date and col_rev and col_units):
        st.warning("Colonnes non reconnues automatiquement. S√©lectionne-les ci-dessous.")
        with st.expander("Diagnostic colonnes CSV"):
            st.write(list(dfj_raw.columns))
        cols = list(dfj.columns)
        col_date  = st.selectbox("Colonne date de premi√®re publication", cols, index=cols.index(col_date) if col_date else 0)
        col_rev   = st.selectbox("Colonne revenus (millions)", cols, index=cols.index(col_rev) if col_rev else 0)
        col_units = st.selectbox("Colonne unit√©s vendues (millions)", cols, index=cols.index(col_units) if col_units else 0)

    work = dfj[[col_date, col_rev, col_units]].rename(columns={
        col_date:  "date_pub",
        col_rev:   "revenus_m",
        col_units: "unites_m"
    }).copy()

    work["Ann√©e"] = pd.to_datetime(work["date_pub"], errors="coerce").dt.year
    mask_na = work["Ann√©e"].isna()
    if mask_na.any():
        work.loc[mask_na, "Ann√©e"] = work.loc[mask_na, "date_pub"].astype(str).str.extract(r"(20\d{2})", expand=False)
    work["Ann√©e"] = pd.to_numeric(work["Ann√©e"], errors="coerce").astype("Int64")

    work["Revenus (millions)"] = work["revenus_m"].apply(_to_float)
    work["Unit√©s vendues (millions)"] = work["unites_m"].apply(_to_float)

    annual = (work.dropna(subset=["Ann√©e"])
                   .groupby("Ann√©e", as_index=False)
                   .agg({"Revenus (millions)": "sum", "Unit√©s vendues (millions)": "sum"}))

    if annual.empty:
        st.error("Aucune donn√©e exploitable apr√®s agr√©gation. V√©rifie le mapping des colonnes.")
        st.stop()

    # Texte AVANT (identique au doc)
    st.markdown("""
    Dans un march√© de plus en plus **concurrentiel** o√π **l‚Äôattention des joueurs est limit√©e**, ce positionnement nuit √† la 
    **visibilit√©** des titres d‚ÄôUbisoft et limite leur capacit√© √† s‚Äôimposer comme des **r√©f√©rences durables**.
    """)
    st.divider()

    # ‚Äî‚Äî‚Äî Titre de section (m√™me niveau que 2.1) ‚Äî‚Äî‚Äî
    st.subheader("2.2. Une d√©pendance √† quelques blockbusters")



    # Graphique s√©ries annuelles
    fig3 = go.Figure()
    fig3.add_trace(go.Scatter(x=annual["Ann√©e"], y=annual["Revenus (millions)"],
                              mode="lines+markers", name="Revenus (millions)", line=dict(width=3)))
    fig3.add_trace(go.Scatter(x=annual["Ann√©e"], y=annual["Unit√©s vendues (millions)"],
                              mode="lines+markers", name="Unit√©s vendues (millions)", yaxis="y2", line=dict(width=3)))
    apply_light_theme(fig3, title_text="√âvolution des revenus et unit√©s vendues par ann√©e",
                      x_title="Ann√©e", y1_title="Revenus (millions)", y2_title="Unit√©s vendues (millions)")
    st.plotly_chart(fig3, use_container_width=True)

    # Texte APR√àS (identique au doc)
    st.markdown("""
    Les donn√©es r√©v√®lent une **forte concentration des revenus** sur quelques titres phares, notamment entre **2014** et **2015**, 
    p√©riode marqu√©e par le lancement d‚Äô√©pisodes majeurs d‚Äô*Assassin‚Äôs Creed* et de *Far Cry*.  
    Cette dynamique s‚Äôest progressivement **estomp√©e**.

    On voit que **chaque jeu contribue fortement** √† la volatilit√© des revenus, confirmant que le **succ√®s d‚ÄôUbisoft repose davantage 
    sur quelques blockbusters** que sur l‚Äôensemble de son catalogue.

    Depuis **2019**, Ubisoft peine √† reproduire de tels succ√®s, probablement impact√©e par la **crise Covid-19**.  
    Le recul de ses revenus annuels s‚Äôexplique en partie par l‚Äôabsence de **nouveaux hits d‚Äôampleur**, capables de porter √† eux seuls 
    l‚Äôexercice financier. Ce ph√©nom√®ne met en lumi√®re une **d√©pendance excessive** √† des **franchises anciennes**, sans r√©elle rel√®ve.

    Ainsi, malgr√© un **catalogue √©tendu**, la **majorit√© des titres publi√©s** g√©n√®rent **peu de valeur individuellement**.  
    Ce **d√©s√©quilibre fragilise la r√©silience** du mod√®le √©conomique, qui repose de fait sur une **minorit√© de succ√®s critiques et commerciaux**.

    Cette observation se **confirme apr√®s analyse crois√©e** du **temps de jeu m√©dian** et des **revenus g√©n√©r√©s par ann√©e**, 
    qui r√©v√®le la m√™me d√©pendance aux quelques titres √† fort impact.
    """)

    # ---------- Temps m√©dian vs revenus (si dispo) ----------
    if not col_medhrs:
        col_medhrs = _find_col(dfj.columns, ["temps median", "temps m√©dian", "median playtime", "temps de jeu"])
    if col_medhrs:
        df_tm = dfj_raw.copy()
        rename_map = {}
        for c in df_tm.columns:
            nc = _norm(c)
            if nc == _norm(col_date):   rename_map[c] = "Premi√®re publication"
            if nc == _norm(col_rev):    rename_map[c] = "Revenus (millions)"
            if nc == _norm(col_medhrs): rename_map[c] = "Temps m√©dian de jeu (heures)"
        df_tm.rename(columns=rename_map, inplace=True)

        needed = {"Premi√®re publication","Revenus (millions)","Temps m√©dian de jeu (heures)"}
        if needed.issubset(df_tm.columns):
            df_tm["Premi√®re publication"] = pd.to_datetime(df_tm["Premi√®re publication"], errors="coerce")
            df_tm["Ann√©e"] = df_tm["Premi√®re publication"].dt.year
            df_tm["Revenus (millions)"] = df_tm["Revenus (millions)"].apply(_to_float)
            df_tm["Temps m√©dian de jeu (heures)"] = df_tm["Temps m√©dian de jeu (heures)"].apply(_to_float)

            df_year = (df_tm.dropna(subset=["Ann√©e"])
                            .groupby("Ann√©e", as_index=False)
                            .agg({"Revenus (millions)": "sum",
                                  "Temps m√©dian de jeu (heures)": "median"}))

            if not df_year.empty:
                fig4 = go.Figure()
                fig4.add_trace(go.Scatter(x=df_year["Ann√©e"], y=df_year["Temps m√©dian de jeu (heures)"],
                                          mode="lines+markers", name="Temps m√©dian de jeu (h)", line=dict(width=3)))
                fig4.add_trace(go.Scatter(x=df_year["Ann√©e"], y=df_year["Revenus (millions)"],
                                          mode="lines+markers", name="Revenus (millions)", yaxis="y2", line=dict(width=3)))
                apply_light_theme(fig4, title_text="Temps m√©dian de jeu vs Revenus (annuel)",
                                  x_title="Ann√©e", y1_title="Temps m√©dian de jeu (h)", y2_title="Revenus (millions)")
                st.plotly_chart(fig4, use_container_width=True)
            # ---------- Bloc texte √† ins√©rer entre les deux graphiques ----------
    st.markdown("""
En effet, **entre 2005 et 2014**, Ubisoft enregistre une **croissance continue** de ces deux indicateurs,
avec un **pic autour de 2014‚Äì2015**. Comme expliqu√© pr√©c√©demment, cette p√©riode correspond √† la sortie de
**titres majeurs**, souvent bien accueillis par la **critique** comme par les **joueurs**, et jouant un
**r√¥le structurant** dans les revenus de l‚Äôentreprise.

**Cependant, apr√®s 2018**, les **revenus chutent significativement**, tandis que le **temps de jeu m√©dian
reste √©lev√©**. Ce d√©calage indique que, malgr√© une baisse de performance √©conomique, Ubisoft **conserve une
base de joueurs fid√®les**, probablement attach√©s √† ses **licences historiques**.

Ce ph√©nom√®ne illustre un **probl√®me de renouvellement d‚Äôoffre** : Ubisoft **capitalise sur ses anciens succ√®s**,
mais **ne parvient plus √† recr√©er l‚Äô√©lan** des pr√©c√©dentes g√©n√©rations de **blockbusters**.
""")
    st.divider()
    st.subheader("2.3. Des mod√®les √©conomiques mal exploit√©s")
    st.markdown(
    "Entre 2013 et 2015, Ubisoft parvient √† capter l‚Äôattention du march√© avec plusieurs initiatives Free-to-Play "
    "et des titres √† fort potentiel multijoueur (*The Mighty Quest for Epic Loot, Trackmania, Brawlhalla*, etc.)."
)

    # ---------- Mod√®les √©conomiques (gratuits vs payants) ----------
    col_model = _find_col(dfj.columns, ["modele", "mod√®le", "business", "monet", "model", "pricing", "f2p", "free", "gratuit"])
    col_price = _find_col(dfj.columns, ["prix", "price"])

    work2 = dfj[[col_date, col_units] + ([col_model] if col_model else []) + ([col_price] if col_price else [])].copy()
    work2.rename(columns={col_date:"date_pub", col_units:"unites"}, inplace=True)
    work2["Ann√©e"] = pd.to_datetime(work2["date_pub"], errors="coerce").dt.year
    work2["Unit√©s vendues (millions)"] = work2["unites"].apply(_to_float)

    def _is_free(row) -> bool:
        if col_model:
            s = str(row[col_model]).lower()
            if any(k in s for k in ["free", "gratuit", "f2p", "free-to-play", "free to play"]):
                return True
        if col_price:
            try:
                p = _to_float(row[col_price])
                if p == 0:
                    return True
            except:
                pass
        return False

    work2["Type"] = work2.apply(lambda r: "Jeux gratuits" if _is_free(r) else "Jeux payants", axis=1)

    g = (work2.dropna(subset=["Ann√©e"])
              .groupby(["Ann√©e","Type"], as_index=False)
              .agg({"Unit√©s vendues (millions)":"sum"}))

    if not g.empty:
        import plotly.graph_objects as go
        wide = g.pivot(index="Ann√©e", columns="Type", values="Unit√©s vendues (millions)").fillna(0.0).sort_index()
        fig5 = go.Figure()
        if "Jeux payants" in wide.columns:
            fig5.add_trace(go.Scatter(x=wide.index, y=wide["Jeux payants"],
                                      mode="lines+markers", name="Jeux payants", line=dict(width=3)))
        if "Jeux gratuits" in wide.columns:
            fig5.add_trace(go.Scatter(x=wide.index, y=wide["Jeux gratuits"],
                                      mode="lines+markers", name="Jeux gratuits", line=dict(width=3, dash="dash")))
        apply_light_theme(fig5, title_text="√âvolution des unit√©s vendues : Jeux gratuits vs payants",
                          x_title="Ann√©e", y1_title="Unit√©s vendues (millions)")
        st.plotly_chart(fig5, use_container_width=True)

        # ---------- Bloc de conclusion (√† ins√©rer √† la fin du chapitre) ----------
    
    st.markdown("""
    Pourtant, cette **dynamique prometteuse** n‚Äôa pas √©t√© p√©rennis√©e. Le **mod√®le freemium**, pourtant porteur sur le long terme
    pour d‚Äôautres √©diteurs (comme *Epic Games* avec *Fortnite*), n‚Äôa **jamais √©t√© solidement ancr√©** dans la strat√©gie
    produit d‚ÄôUbisoft.

    Cette **incapacit√© √† renouveler les formats**, √† proposer des **exp√©riences √©conomiques innovantes** ou √† **s‚Äôadapter aux tendances**
    (*abonnement*, *cross-platform*, *multijoueur comp√©titif*, etc.) **risque d‚Äôisoler progressivement Ubisoft** d‚Äôune partie de la communaut√©,
    notamment les **joueurs plus jeunes** ou **plus actifs sur mobile et PC**.
    """)
    st.divider()

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# PAGE 4 : PERCEPTION ET CRITIQUE ‚Äî RUPTURE AVEC LES JOUEURS
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
elif page == "Perception et critique : la rupture avec les joueurs":
    import pandas as pd
    import numpy as np
    import re
    import matplotlib.pyplot as plt
    import seaborn as sns

    st.title("üß© Perception et critique : la rupture avec les joueurs")
    st.markdown("""
    Au-del√† des performances financi√®res et des strat√©gies de d√©veloppement,  
    l‚Äôanalyse de la **r√©ception critique** des jeux Ubisoft apporte un √©clairage essentiel.  

    En observant les notes attribu√©es par la **presse sp√©cialis√©e** et les **joueurs** sur des plateformes comme **Metacritic**,  
    on met en √©vidence une **communaut√© de joueurs** qui semble **l√©g√®rement plus polaris√©e**  
    et parfois **pr√™te √† noter des jeux √† 0**.
    """)


    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Lecture directe du CSV local
    @st.cache_data
    def load_scores():
        tries = [
            dict(sep=",", encoding="utf-8"),
            dict(sep=";", encoding="utf-8"),
            dict(sep=",", encoding="utf-8-sig"),
            dict(sep=";", encoding="utf-8-sig"),
            dict(sep=",", encoding="cp1252"),
            dict(sep=";", encoding="cp1252"),
        ]
        last_err = None
        for opt in tries:
            try:
                return pd.read_csv("ubisoft_scores.csv", engine="python", **opt)
            except Exception as e:
                last_err = e
        st.error(f"‚ö†Ô∏è Impossible de lire `ubisoft_scores.csv`. V√©rifie qu'il est bien plac√© √† c√¥t√© de `app.py`. D√©tails : {last_err}")
        st.stop()

    raw = load_scores()

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ V√©rification des colonnes attendues
    expected_cols = {"Press_Score", "Users_Score"}
    if not expected_cols.issubset(raw.columns):
        st.error("‚ö†Ô∏è Le fichier CSV doit contenir les colonnes **Press_Score** et **Users_Score**.")
        st.stop()

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Nettoyage des donn√©es
    def _to_num(x):
        if pd.isna(x): return np.nan
        s = str(x).strip().lower()
        if s in {"tbd", "na", "n/a", "none", "null", "-", ""}:
            return np.nan
        s = s.replace("\u202f", "").replace("\xa0", "").replace(",", ".")
        s = re.sub(r"[^0-9\.\-]", "", s)
        try:
            return float(s)
        except:
            return np.nan

    df_notes = pd.DataFrame({
        "Press_Score": raw["Press_Score"].apply(_to_num),
        "Users_Score": raw["Users_Score"].apply(_to_num),
    }).dropna()

    # Conversion auto 0‚Äì100 ‚Üí 0‚Äì10
    if df_notes["Press_Score"].max() > 10:
        df_notes["Press_Score"] /= 10.0
    if df_notes["Users_Score"].max() > 10:
        df_notes["Users_Score"] /= 10.0

    # Filtre borne [0,10]
    df_notes = df_notes[
        (df_notes["Press_Score"].between(0, 10)) &
        (df_notes["Users_Score"].between(0, 10))
    ]

    if df_notes.empty:
        st.error("‚ö†Ô∏è Aucune donn√©e exploitable apr√®s nettoyage (scores attendus entre 0 et 10).")
        st.stop()

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Stats descriptives (COUNT + MEAN uniquement)
    st.subheader(" Statistiques descriptives")
    stats = df_notes.describe().loc[["count", "mean"]].round(3)
    st.dataframe(stats, use_container_width=True)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Graphiques : Presse vs Joueurs
    st.subheader(" Comparaison des distributions")
    x_min, x_max = 0, 10
    sns.set_style("whitegrid")

    fig, axs = plt.subplots(2, 1, figsize=(10, 8), sharex=True)

    # Presse
    sns.histplot(df_notes["Press_Score"], bins=20, kde=True, color="#4CAF50", ax=axs[0])
    axs[0].set_title("Distribution des notes de la Presse (sur 10)", fontsize=12)
    axs[0].set_ylabel("Nombre de jeux")
    axs[0].set_xlim(x_min, x_max)

    # Joueurs
    sns.histplot(df_notes["Users_Score"], bins=20, kde=True, color="#87CEEB", ax=axs[1])
    axs[1].set_title("Distribution des notes utilisateurs (sur 10)", fontsize=12)
    axs[1].set_xlabel("Notes")
    axs[1].set_ylabel("Nombre de jeux")
    axs[1].set_xlim(x_min, x_max)

    plt.tight_layout()
    st.pyplot(fig)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Analyse rapide
    st.subheader(" Analyse")
    st.markdown("""
    - **Presse** : notes majoritairement concentr√©es entre **6 et 8**, refl√©tant une √©valuation globalement positive.
    - **Joueurs** : distribution plus **√©tal√©e**, avec davantage de notes tr√®s basses ‚Üí signe d'une **polarisation**.
    - Cet √©cart r√©v√®le une diff√©rence de perception : Ubisoft convainc la presse mais divise parfois sa communaut√©.
    """)
    # ‚Äî‚Äî‚Äî D√©tection Year + agr√©gations annuelles
    import unicodedata, re
    def _norm(s: str) -> str:
        s = unicodedata.normalize("NFKD", str(s))
        s = "".join(c for c in s if not unicodedata.combining(c))
        return re.sub(r"[\s\-_\/]+", " ", s).strip().lower()

    def _extract_year_column(df: pd.DataFrame) -> pd.Series | None:
        # 1) colonnes de date
        for c in df.columns:
            n = _norm(c)
            if any(k in n for k in ["release", "premiere", "publication", "date", "year", "annee", "ann√©e"]):
                y = pd.to_datetime(df[c], errors="coerce").dt.year
                if y.notna().sum() > 0:
                    return y
        # 2) colonnes num√©riques d√©j√† en ann√©es
        for c in df.columns:
            if pd.api.types.is_numeric_dtype(df[c]):
                y = pd.to_numeric(df[c], errors="coerce")
                if ((y >= 1990) & (y <= 2035)).sum() > 0:
                    return y
        return None

    year_series = _extract_year_column(raw)
    if year_series is None:
        st.warning("Aucune colonne de date/ann√©e reconnue : les graphiques temporels ne peuvent pas √™tre trac√©s.")
    else:
        work = pd.DataFrame({
            "Year": year_series,
            "Press_Score": df_notes["Press_Score"].values,  # scores d√©j√† nettoy√©s/ramen√©s sur 10
            "Users_Score": df_notes["Users_Score"].values,
        }).dropna()
        work = work[(work["Year"] >= 1995) & (work["Year"] <= 2035)]

        yearly = (work.groupby("Year", as_index=False)
                        .agg(Press=("Press_Score","mean"),
                             Users=("Users_Score","mean"))
                        .sort_values("Year"))

        # ‚Äî‚Äî‚Äî Graphique 1 : courbes annuelles
        st.subheader(" Notes moyennes par ann√©e ‚Äî Presse vs Joueurs")
        fig_line, axl = plt.subplots(figsize=(10, 5))
        axl.plot(yearly["Year"], yearly["Press"], marker="o", linewidth=2.2, label="Presse", color="#2E7D32")
        axl.plot(yearly["Year"], yearly["Users"], marker="o", linewidth=2.2, label="Joueurs", color="#FB8C00")
        axl.set_xlabel("Ann√©e de sortie"); axl.set_ylabel("Note moyenne (sur 10)")
        axl.grid(True, linestyle="--", alpha=0.35)
        axl.legend(title="Source", frameon=True)

        # rep√®re ¬´ d√©crochage ¬ª (si l'ann√©e est dans la s√©rie)
        if (yearly["Year"] >= 2014).any() and (yearly["Year"] <= 2014).any():
            axl.axvline(2014, color="#757575", linestyle="--", alpha=0.6)
            ymin, ymax = axl.get_ylim()
            axl.text(2014 + 0.2, ymin + 0.05*(ymax-ymin),
                     "D√©crochage des notes des joueurs", fontsize=9, color="#616161")

        st.pyplot(fig_line)
        # ‚Äî‚Äî‚Äî Graphique 2 : √©cart moyen annuel (Users ‚àí Press)
        st.subheader(" √âcart moyen entre notes utilisateurs et presse ")
        delta = yearly.copy()
        delta["Diff"] = delta["Users"] - delta["Press"]

        # couleurs: bleu si positif, d√©grad√© de rouge si n√©gatif
        import matplotlib as mpl
        reds = mpl.cm.get_cmap("Reds")
        neg_vals = delta["Diff"].clip(upper=0).abs()
        if neg_vals.max() == 0:
            neg_norm = np.zeros_like(neg_vals)
        else:
            neg_norm = neg_vals / neg_vals.max()

        colors = []
        for d, nn in zip(delta["Diff"], neg_norm):
            if d >= 0:
                colors.append("#1f77b4")          # bleu (joueurs plus g√©n√©reux)
            else:
                colors.append(reds(0.35 + 0.55*nn))  # rouge plus sombre si l‚Äô√©cart est grand

        fig_bar, axb = plt.subplots(figsize=(10, 5))
        axb.bar(delta["Year"], delta["Diff"], color=colors, width=0.8, edgecolor="none")
        axb.axhline(0, color="black", linewidth=1)
        axb.set_xlabel("Ann√©e de sortie"); axb.set_ylabel("Score delta (Users ‚àí Press)")
        axb.grid(axis="y", linestyle="--", alpha=0.35)

        # petite l√©gende manuelle
        from matplotlib.patches import Patch
        legend_elems = [
            Patch(facecolor="#1f77b4", label="Joueurs plus g√©n√©reux que la presse"),
            Patch(facecolor=reds(0.8), label="Joueurs plus critiques que la presse"),
        ]
        axb.legend(handles=legend_elems, title="Interpr√©tation des couleurs", frameon=True)

        st.pyplot(fig_bar)
    st.markdown("""


Historiquement, les jeux Ubisoft ont re√ßu des √©valuations relativement proches entre la **presse** et les **joueurs**. 
Jusqu‚Äôen **2014**, la moyenne des notes utilisateurs est stable autour de **7/10**, tandis que la presse affiche 
g√©n√©ralement des scores entre **7 et 8/10**. Les √©carts sont mod√©r√©s, et les critiques convergent globalement.

√Ä partir de **2015**, une **fracture de perception** commence √† se dessiner : les joueurs deviennent plus critiques, 
attribuant des notes **significativement inf√©rieures** √† celles de la presse. Cette tendance s‚Äôaccentue au fil des ann√©es, 
jusqu‚Äô√† atteindre un **√©cart moyen de ‚Äì2,3 points** entre les deux types d‚Äô√©valuateurs en **2022**. Dans certains cas, 
les utilisateurs attribuent des notes **tr√®s basses (0 √† 4/10)**, souvent motiv√©es par une frustration li√©e √† la 
**qualit√© technique** ou √† la **d√©ception** vis-√†-vis des promesses initiales.

La presse, quant √† elle, reste globalement **mod√©r√©e** dans ses notations, avec peu d‚Äô√©volutions √† la baisse. 
Ce d√©calage persistant entre **qualit√© per√ßue par les joueurs** et **reconnaissance critique** devient un marqueur 
structurel de la **crise** que traverse Ubisoft. Il t√©moigne d‚Äôun **d√©salignement** entre l‚Äôexp√©rience r√©elle des 
utilisateurs et le produit livr√©, aliment√© par des √©l√©ments r√©currents dans les critiques : **manque d‚Äôinnovation**, 
**gameplay r√©p√©titif**, **bugs techniques**, ou encore **promesses non tenues**.
""")

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # 3) Top & Flop Ubisoft ‚Äì Score moyen global (presse + utilisateurs)
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    import re, unicodedata
    import matplotlib.pyplot as plt
    import seaborn as sns

    st.subheader(" Top & Flop Ubisoft ‚Äì Score moyen global (presse + utilisateurs)")

    # --- Helpers pour retrouver les colonnes "Name", "Platform" et "Year" si elles ne sont pas d√©j√† dans df_notes
    def _norm(s: str) -> str:
        s = unicodedata.normalize("NFKD", str(s))
        s = "".join(c for c in s if not unicodedata.combining(c))
        return re.sub(r"[\s\-_\/]+", " ", s).strip().lower()

    def _extract_year_column(df: pd.DataFrame) -> pd.Series | None:
        # 1) colonnes de date
        for c in df.columns:
            n = _norm(c)
            if any(k in n for k in ["release", "premiere", "publication", "date", "year", "annee", "ann√©e"]):
                y = pd.to_datetime(df[c], errors="coerce").dt.year
                if y.notna().sum() > 0:
                    return y
        # 2) colonnes num√©riques d√©j√† en ann√©es
        for c in df.columns:
            if pd.api.types.is_numeric_dtype(df[c]):
                y = pd.to_numeric(df[c], errors="coerce")
                if ((y >= 1990) & (y <= 2035)).sum() > 0:
                    return y
        return None

    # On part de df_notes (d√©j√† nettoy√© + ramen√© sur 10) et du DataFrame brut 'raw' lu en d√©but de page 4
    df_plot = df_notes.copy()

    # Ajoute Year si manquant
    if "Year" not in df_plot.columns:
        y = _extract_year_column(raw)
        if y is not None:
            df_plot["Year"] = y
        else:
            st.error("Impossible d‚Äôidentifier la colonne Ann√©e. Ajoute une colonne 'Year' ou une date de sortie dans le CSV.")
            st.stop()

    # Ajoute Name si manquant
    if "Name" not in df_plot.columns:
        name_col = next((c for c in raw.columns if _norm(c) in {"name","titre","title","game","jeu"} 
                         or any(k in _norm(c) for k in ["name","title","game","jeu","titre"])), None)
        if name_col:
            df_plot["Name"] = raw[name_col]
        else:
            df_plot["Name"] = [f"Jeu {i}" for i in range(len(df_plot))]

    # Ajoute Platform si manquant
    if "Platform" not in df_plot.columns:
        plat_col = next((c for c in raw.columns if any(k in _norm(c) for k in ["platform","console","system"])), None)
        df_plot["Platform"] = raw[plat_col] if plat_col else "N/A"

    # Ajoute Score_Avg si manquant
    if "Score_Avg" not in df_plot.columns:
        df_plot["Score_Avg"] = df_plot[["Press_Score","Users_Score"]].mean(axis=1)

    # --- Ton code adapt√© √† Streamlit ---
    # Filtrer les jeux sortis depuis 2015
    df_notes_recent = df_plot[df_plot["Year"] >= 2015].copy()

    # Top 10 des jeux Ubisoft selon score_avg
    top_avg = (df_notes_recent.sort_values(by="Score_Avg", ascending=False)
               .drop_duplicates(subset=["Name","Platform"])
               .head(10))

    # Flop 10 des jeux Ubisoft selon score_avg
    flop_avg = (df_notes_recent.sort_values(by="Score_Avg", ascending=True)
                .drop_duplicates(subset=["Name","Platform"])
                .head(10))

    # Fusion pour plot
    topflop_avg = pd.concat([top_avg.assign(cat="Top"), flop_avg.assign(cat="Flop")], ignore_index=True)

    if topflop_avg.empty:
        st.warning("Aucune donn√©e apr√®s filtrage (Year ‚â• 2015). V√©rifie les colonnes Year/Name/Platform.")
    else:
        # Tri de l‚Äôaffichage (du plus faible au plus fort, puis inversion de l‚Äôaxe Y pour avoir les meilleurs en haut)
        order_names = topflop_avg.sort_values("Score_Avg", ascending=True)["Name"]

        fig, ax = plt.subplots(figsize=(12, 8))
        sns.barplot(
            data=topflop_avg,
            y="Name",
            x="Score_Avg",
            hue="cat",
            dodge=False,
            order=order_names,
            palette={"Top": "green", "Flop": "red"},
            ax=ax
        )
        ax.set_title("Top & Flop Ubisoft ‚Äì Score moyen global (presse + utilisateurs)", fontsize=13)
        ax.set_xlabel("Score moyen (/10)")
        ax.set_ylabel("Jeu")
        ax.grid(axis="x", linestyle="--", alpha=0.35)
        ax.legend(title="Cat√©gorie", frameon=True)
        ax.invert_yaxis()  # meilleurs en haut

        # Ajout des valeurs au bout des barres
        for p in ax.patches:
            width = p.get_width()
            y = p.get_y() + p.get_height() / 2
            ax.text(width + 0.05, y, f"{width:.1f}", va="center", fontsize=9)

        plt.tight_layout()
        st.pyplot(fig)
    # ‚Äî‚Äî‚Äî Texte d'analyse : Top & Flop Ubisoft 2015‚Äì2025
    st.markdown("""
Sur la p√©riode **2015‚Äì2025**, l‚Äô√©tude des **notes moyennes globales** (*presse + utilisateurs*) met en √©vidence une
**tendance pr√©occupante** : les meilleurs jeux Ubisoft r√©cents ne sont pas ceux qui b√©n√©ficient du plus fort
**soutien marketing**, ni ceux issus des **franchises historiques**.

Parmi les titres les mieux re√ßus, on retrouve notamment **Beyond Good & Evil 20th Anniversary Edition** ou
**Prince of Persia: The Lost Crown** ‚Äì des jeux moins expos√©s m√©diatiquement.  
√Ä l‚Äôinverse, plusieurs **blockbusters tr√®s attendus**, √† **gros budget**, √©chouent √† convaincre :
**Ghost Recon Breakpoint**, **The Settlers: New Allies**, ou encore **Just Dance 2024 Edition**
re√ßoivent des notes particuli√®rement basses, en d√©calage avec leurs ambitions.

Ce ph√©nom√®ne appuie davantage sur la **diminution de la confiance des joueurs** envers les grands lancements Ubisoft.
L‚Äôun des exemples les plus embl√©matiques de cette rupture est le cas de **Skull & Bones**, que nous allons analyser
dans la derni√®re partie.
""")

    # ‚Äî‚Äî‚Äî Barre de s√©paration avant la section 3.3
    st.markdown("---")

    # ‚Äî‚Äî‚Äî Partie 3.3 : Le cas Skull & Bones
    st.subheader("3.3. Le cas Skull & Bones : un √©chec embl√©matique")

    st.markdown("""
L‚Äô√©pisode le plus marquant de cette rupture entre Ubisoft et sa communaut√© est incarn√© par **Skull & Bones**,
consid√©r√© comme l‚Äôun des plus gros √©checs r√©cents de l‚Äô√©diteur.  
Ce jeu, cens√© capitaliser sur le succ√®s de *Assassin‚Äôs Creed IV: Black Flag* et sur l‚Äôengouement pour les
**th√©matiques pirates**, a connu un **d√©veloppement chaotique** √©tal√© sur pr√®s de **10 ans**.  
√Ä sa sortie, il recueille une **note utilisateur catastrophique de 3/10**, tandis que la presse reste
**mod√©r√©ment indulgente**.

Un **nuage de mots** g√©n√©r√© √† partir des critiques utilisateurs sur *Metacritic* permet de mettre en lumi√®re
cette perception.  
Les termes les plus fr√©quents parlent d‚Äôeux-m√™mes :  
*‚Äúboring‚Äù*, *‚Äúrepetitive‚Äù*, *‚Äúmoney‚Äù*, *‚Äúcombat‚Äù*, *‚Äúwaste‚Äù*, *‚Äúgameplay‚Äù*, *‚Äúdisappointing‚Äù*, *‚ÄúBlack Flag‚Äù*, etc.

Ils illustrent une combinaison de **d√©ception**, **d‚Äôennui** et de **frustration √©conomique**.  
Beaucoup de joueurs font explicitement r√©f√©rence √† *Black Flag*, renfor√ßant la comparaison avec un jeu sur une
**th√©matique proche**, per√ßu comme **bien mieux r√©ussi**, pourtant sorti **dix ans plus t√¥t**.
""")
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Nuage de mots n√©gatifs ‚Äî Skull & Bones (stopwords fournis + suppression "skull" et "bones")
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    import sys
    import subprocess
    import string
    import unicodedata
    import re
    import pandas as pd
    import matplotlib.pyplot as plt
    from wordcloud import WordCloud, STOPWORDS
    from textblob import TextBlob

    st.subheader(" Nuage de mots des critiques n√©gatives ‚Äî Skull & Bones")

    # --- Installer automatiquement wordcloud & textblob si manquants
    def _ensure_package(mod_name, pip_name=None):
        try:
            __import__(mod_name)
        except ModuleNotFoundError:
            with st.spinner(f"Installation de `{pip_name or mod_name}`‚Ä¶"):
                subprocess.check_call([sys.executable, "-m", "pip", "install", pip_name or mod_name])
            __import__(mod_name)

    _ensure_package("wordcloud")
    _ensure_package("textblob")

    # --- Lecture CSV critiques
    @st.cache_data
    def _read_critiques():
        tries = [
            dict(sep=",", encoding="utf-8"),
            dict(sep=";", encoding="utf-8"),
            dict(sep=",", encoding="utf-8-sig"),
            dict(sep=";", encoding="utf-8-sig"),
            dict(sep=",", encoding="cp1252"),
            dict(sep=";", encoding="cp1252"),
            dict(sep="\t", encoding="utf-8"),
        ]
        for path in ["ubisoft_critiques.csv", "data/ubisoft_critiques.csv"]:
            for opt in tries:
                try:
                    return pd.read_csv(path, engine="python", **opt)
                except Exception:
                    continue
        raise RuntimeError("‚ö†Ô∏è Fichier `ubisoft_critiques.csv` introuvable.")

    try:
        dfc_raw = _read_critiques()
    except Exception as e:
        st.error(f"‚ö†Ô∏è {e}")
        st.stop()

    # --- D√©tection colonnes Jeu / Critique
    def _norm(s: str) -> str:
        s = unicodedata.normalize("NFKD", str(s))
        s = "".join(c for c in s if not unicodedata.combining(c))
        return re.sub(r"[\s\-_\/]+", " ", s).strip().lower()

    cols_map = {_norm(c): c for c in dfc_raw.columns}
    col_game = next((cols_map[k] for k in ["jeu","name","title","game","nom"] if k in cols_map), None)
    col_text = next((cols_map[k] for k in ["critique","review","user review","user_review","comment","texte","text"] if k in cols_map), None)
    if not (col_game and col_text):
        st.error("‚ö†Ô∏è Le CSV des critiques doit contenir une colonne **Jeu/Name** et **Critique/Review**.")
        st.stop()

    dfc = dfc_raw[[col_game, col_text]].rename(columns={col_game:"Jeu", col_text:"Critique"}).dropna()

    # --- Filtrer uniquement Skull & Bones
    jeu_cible = "Skull and Bones"
    df_skull = dfc[dfc["Jeu"].astype(str).str.lower().str.contains("skull")]

    if df_skull.empty:
        st.warning("‚ö†Ô∏è Aucune critique trouv√©e pour 'Skull & Bones'. V√©rifie ton CSV.")
    else:
        # --- Garder uniquement les critiques NEGATIVES
        critiques_neg = df_skull["Critique"].dropna().astype(str)
        critiques_neg = critiques_neg[critiques_neg.apply(lambda x: TextBlob(x).sentiment.polarity < 0)]

        # --- Nettoyage texte
        texte = " ".join(critiques_neg.str.lower())
        texte = texte.translate(str.maketrans("", "", string.punctuation))

        # --- Stopwords EXACTS : uniquement ta liste + suppression des noms "skull" et "bones"
        custom_stopwords = set(STOPWORDS)
        custom_stopwords.update([
            'game', 'games', 'ubisoft', 'play', 'player', 'playing',
            'dlc', 'edition', 'content', 'series', 'experience',
            'version', 'new', 'like', 'one', 'ship', 'pirate','fun','combat',
            'skull', 'bones'  # ‚Üê Ajout√©s ici pour ne PAS les afficher
        ])

        # --- Liste des mots cl√©s √† mettre en ROUGE vif
        highlight_words = {
            "boring": "#d62728",
            "repetitive": "#d62728",
            "money": "#d62728",
            "combat": "#d62728",
            "waste": "#d62728",
            "gameplay": "#d62728",
            "disappointing": "#d62728",
            "black": "#d62728",
            "flag": "#d62728"
        }

        # --- Fonction de coloration dynamique des mots
        def color_function(word, **kwargs):
            return highlight_words.get(word.lower(), "lightcoral")

        # --- G√©n√©ration du WordCloud (style projet)
        wordcloud = WordCloud(
            width=1200,
            height=700,
            background_color="white",
            stopwords=custom_stopwords,
            color_func=color_function
        ).generate(texte)

        # --- Affichage graphique
        fig, ax = plt.subplots(figsize=(12, 8))
        ax.imshow(wordcloud, interpolation="bilinear")
        ax.axis("off")
        plt.tight_layout()
        st.pyplot(fig)
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # üìä Section 3.4 : Un d√©salignement total entre budget, dur√©e et r√©sultat
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    import matplotlib.pyplot as plt
    import seaborn as sns
    import pandas as pd

    # --- Titre de la section
    st.markdown("## 3.4. Un d√©salignement total entre budget, dur√©e et r√©sultat")

    # ‚Äî‚Äî‚Äî Texte introductif (au-dessus du graphique budget)
    st.markdown("""
Ce qui rend **Skull & Bones** encore plus probl√©matique, c‚Äôest la **disproportion**
entre les **moyens engag√©s** et la **qualit√© per√ßue**.  
Avec un **budget estim√© √† plus de 200 millions de dollars** *(voire **500 M$** selon certaines sources,
notamment d‚Äôanciens employ√©s d‚ÄôUbisoft)*, le jeu se classe parmi les **plus ambitieux de l‚Äôindustrie**,  
aux c√¥t√©s de productions ayant connu un **succ√®s √©norme** comme **GTA V** ou **Call of Duty: Modern Warfare**.
""")

    # --- Donn√©es fictives de l'√©tude AAA (√† adapter selon tes fichiers CSV si n√©cessaire)
    data_budget = {
        "Jeu": [
            "Assassin's Creed II", "Far Cry 3", "The Last of Us Part II",
            "FIFA 23", "Elden Ring", "The Legend of Zelda: BOTW",
            "Skull and Bones", "Call of Duty: Modern Warfare (2019)",
            "GTA V", "Red Dead Redemption 2"
        ],
        "Budget": [80, 90, 110, 120, 130, 150, 200, 220, 265, 350]
    }

    df_budget = pd.DataFrame(data_budget)

    # --- Cr√©ation du graphique
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.barplot(
        data=df_budget,
        y="Jeu",
        x="Budget",
        palette=["#6baed6" if jeu != "Skull and Bones" else "#fdae6b" for jeu in df_budget["Jeu"]],
        ax=ax
    )

    # --- Ligne rouge verticale sur le budget de Skull & Bones
    ax.axvline(200, color="red", linestyle="--", linewidth=2, label="Budget Skull & Bones")

    # --- Personnalisation graphique
    ax.set_title("Budgets de production des jeux AAA", fontsize=14, fontweight="bold")
    ax.set_xlabel("Budget (en millions $)")
    ax.set_ylabel("Jeu")
    ax.legend()

    # --- Affichage
    st.pyplot(fig)
    # ‚Äî‚Äî‚Äî Texte d‚Äôinterpr√©tation (apr√®s le graphique budget)
    st.markdown("""
En comparant la **dur√©e de d√©veloppement**, le **budget** et la **note Metacritic** de ces jeux,
on observe que **Skull & Bones** se positionne √† l‚Äô**extr√™me** : **co√ªteux**, **le plus long √† produire**,
avec **le score critique le plus bas**.
""")
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Dur√©e de D√©veloppement vs Note Metacritic (bulles = budget) ‚Äî version Seaborn/Matplotlib pour Streamlit
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    import pandas as pd
    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    import streamlit as st

    st.subheader(" Dur√©e de D√©veloppement vs Note Metacritic ‚Äî üí∞ Taille des bulles = Budget de d√©veloppement")

    @st.cache_data
    def load_aaa():
        # Charge ton fichier tel quel (m√™mes noms de colonnes que dans ton code)
        tries = [
            dict(sep=",", encoding="utf-8"),
            dict(sep=";", encoding="utf-8"),
            dict(sep=",", encoding="utf-8-sig"),
            dict(sep=";", encoding="utf-8-sig"),
            dict(sep=",", encoding="cp1252"),
            dict(sep=";", encoding="cp1252"),
            dict(sep="\t", encoding="utf-8"),
        ]
        last_err = None
        for path in ["jeux_AAA_metacritic_only.csv", "data/jeux_AAA_metacritic_only.csv"]:
            for opt in tries:
                try:
                    df = pd.read_csv(path, engine="python", **opt)
                    return df
                except Exception as e:
                    last_err = e
        raise RuntimeError(f"Impossible de lire le CSV : {last_err}")

    # ‚ûú On suppose que ton CSV a bien les colonnes : title, publisher, budget_musd, development_years, metacritic_score
    df_full = load_aaa()
    required = {"title", "publisher", "budget_musd", "development_years", "metacritic_score"}
    if not required.issubset(df_full.columns):
        st.error(f"Colonnes attendues manquantes. Il faut au minimum : {sorted(required)}")
        st.stop()

    # ‚Äî Graphique identique √† ton code
    plt.figure(figsize=(14, 8))
    sns.set(style="whitegrid", font_scale=1.1)

    # Palette dynamique bas√©e sur le nombre d'√©diteurs
    n_publishers = df_full["publisher"].nunique()
    palette = sns.color_palette("tab10", n_colors=n_publishers)

    plot = sns.scatterplot(
        data=df_full,
        x="development_years",
        y="metacritic_score",
        hue="publisher",
        size="budget_musd",
        sizes=(200, 2000),
        alpha=0.9,
        edgecolor="black",
        linewidth=0.5,
        palette=palette,
        legend="brief"
    )

    # Titres des jeux au centre des bulles (comme ton code)
    for _, row in df_full.iterrows():
        plt.text(
            row["development_years"],
            row["metacritic_score"],
            row["title"],
            fontsize=10,
            ha="center",
            va="center",
            color="black",
            weight="bold",
        )

    # Mise en page (identique √† l‚Äôesprit de ton snippet)
    plt.title("üéÆ Dur√©e de D√©veloppement vs Note Metacritic\nüí∞ Taille des bulles = Budget de d√©veloppement",
              fontsize=16, weight="bold")
    plt.xlabel("Dur√©e de d√©veloppement (ann√©es)", fontsize=12)
    plt.ylabel("Note Metacritic", fontsize=12)
    plt.grid(True, linestyle="--", alpha=0.6)

    # L√©gendes sur la droite
    plt.legend(bbox_to_anchor=(1.05, 1), loc="upper left",
               title="√âditeur / Budget", borderaxespad=1)

    # Petites marges pour √©viter de couper les bulles/labels
    plt.margins(x=0.08, y=0.06)

    # Optionnel : forcer un peu de marge en X pour que tout soit bien ‚Äúentier‚Äù
    xmin, xmax = df_full["development_years"].min(), df_full["development_years"].max()
    plt.xlim(xmin - 0.5, xmax + 1.0)

    plt.tight_layout()

    # ‚ûú Affichage Streamlit
    st.pyplot(plt.gcf(), clear_figure=True)
    st.markdown("""
Ce graphique met en lumi√®re un d√©calage profond entre effort, co√ªt et valeur livr√©e. Il constitue un cas d‚Äô√©cole d‚Äô√©chec produit, qui interroge autant la strat√©gie d‚ÄôUbisoft que sa capacit√© √† piloter efficacement des projets √† long terme.
""")

    st.divider()

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# PAGE 5 : CONCLUSION ‚Äî texte identique au screenshot
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
elif page == "Conclusion":
    st.title("Conclusion")

    st.markdown("""
L‚Äôensemble des analyses men√©es dans ce projet met en lumi√®re un constat clair : la chute d‚ÄôUbisoft ne s‚Äôexplique pas par une crise g√©n√©ralis√©e du secteur du jeu vid√©o, mais bien par des faiblesses propres √† l‚Äôentreprise. Si l‚Äô√©diteur continue de produire un volume √©lev√© de titres chaque ann√©e, cette strat√©gie ne se traduit plus par une rentabilit√© suffisante. Depuis pr√®s d‚Äôune d√©cennie, les signaux d‚Äôalerte sont visibles, notamment √† travers une rupture croissante entre la promesse marketing des jeux et leur r√©ception par les joueurs.


                
Plus pr√©occupant encore, les projets les plus ambitieux ‚Äî tant en dur√©e de d√©veloppement qu‚Äôen investissement financier ‚Äî figurent aujourd‚Äôhui parmi les plus s√©v√®rement critiqu√©s. Cette anomalie entre les moyens d√©ploy√©s et la qualit√© per√ßue traduit une perte de coh√©rence entre la strat√©gie de production et les attentes du march√©.

Dans ce contexte, Ubisoft doit imp√©rativement repenser deux dimensions centrales de son organisation : sa capacit√© √† piloter des projets sur le long terme de mani√®re agile et r√©aliste, et sa facult√© √† int√©grer de mani√®re proactive les retours et attentes de ses communaut√©s de joueurs.

Pour inverser cette tendance, plusieurs pistes peuvent √™tre envisag√©es. Il appara√Æt essentiel d‚Äôam√©liorer l‚Äôefficience op√©rationnelle en r√©-alignant la masse salariale avec les ambitions r√©elles et la performance attendue, tout en identifiant les studios ou projets structurellement sous-performants. Il est √©galement crucial de mieux valoriser l‚Äôengagement des joueurs en exploitant les signaux faibles issus des critiques, des forums ou des donn√©es d‚Äôusage afin d‚Äôorienter les d√©cisions produit de mani√®re plus pertinente.

Par ailleurs, Ubisoft gagnerait √† repenser ses mod√®les √©conomiques, en redonnant une place au freemium lorsque cela est pertinent, ou en explorant des formats hybrides comme les abonnements ou les contenus additionnels. Enfin, la d√©pendance √† des blockbusters √† tr√®s long d√©veloppement devrait √™tre r√©√©valu√©e, au profit de cycles plus courts, plus agiles, et potentiellement plus en phase avec les √©volutions du march√©                
                """)
    st.divider()
    st.divider()
    

# Annexe m√©thodologique ‚Äî petite police + italique
    st.markdown(
    """
    <style>
      .annexe-ux { font-size: 0.92rem; font-style: italic; line-height: 1.55; }
      .annexe-ux h3 { font-size: 1.08rem; font-style: italic; margin: 0 0 0.6rem 0; }
      .annexe-ux p { margin: 0 0 0.6rem 0; }
      .annexe-ux strong { font-style: normal; } /* garder les sous-titres en gras lisibles */
    </style>
    <div class="annexe-ux">
      <h3>Annexe m√©thodologique</h3>

      <p>Pour mieux comprendre le d√©clin d‚ÄôUbisoft, nous avons entrepris une approche en trois volets, m√™lant analyse financi√®re, exploration des performances des jeux, et √©tude de leur r√©ception critique.</p>

      <p><strong>I. Une plong√©e dans les chiffres : l‚Äôanalyse financi√®re comparative</strong><br/>
      Notre premi√®re √©tape fut de comparer l‚Äô√©volution boursi√®re d‚ÄôUbisoft √† celle de deux ETF embl√©matiques du secteur : ESPO et HERO. Gr√¢ce √† la plateforme TradingView, nous avons recueilli les donn√©es couvrant la p√©riode 2018 √† 2024.<br/>
      Pour les analyser, nous avons mobilis√© les capacit√©s de LLM coupl√©es √† une recherche documentaire rigoureuse.<br/>
      R√©sultat : un jeu de donn√©es financier complet, tra√ßant les courbes de valeur de l‚Äôaction Ubisoft et de nos deux ETF de r√©f√©rence.<br/>
      <em>Source : Site TradingView</em><br/>
      <a href="https://fr.tradingview.com/chart/OHym2NDq/?symbol=NASDAQ%3AESPO">ESPO</a> ;
      <a href="https://fr.tradingview.com/chart/OHym2NDq/?symbol=NASDAQ%3AHERO">HERO</a> ;
      <a href="https://fr.tradingview.com/chart/OHym2NDq/?symbol=EUROTLX%3A4UBI">4UBI</a>
      </p>

      <p><strong>II. Explorer les performances concr√®tes : les jeux Ubisoft √† la loupe</strong><br/>
      Nous nous sommes ensuite int√©ress√©s aux performances des jeux publi√©s par Ubisoft entre 1995 et 2025.<br/>
      Pour ce faire, nous avons utilis√© le site VG Insights, une base de donn√©es sp√©cialis√©e, afin d‚Äôextraire les informations-cl√©s : √©diteurs, volumes de jeux, etc.<br/>
      Cette extraction a √©t√© automatis√©e gr√¢ce √† des scripts bas√©s sur BeautifulSoup et Selenium, ce qui nous a permis de constituer deux jeux de donn√©es ‚Äì l‚Äôun d√©di√© aux √©diteurs , l‚Äôautre aux jeux eux-m√™mes.<br/>
      <em>Source : Site VG insights :</em><br/>
      <a href="https://vginsights.com/publishers-database">https://vginsights.com/publishers-database</a> &amp;
      <a href="https://vginsights.com/publisher/8/ubisoft">https://vginsights.com/publisher/8/ubisoft</a>
      </p>

      <p><strong>III. Ce que le public en pense : critiques et perception</strong><br/>
      Enfin, pour comprendre la r√©ception des jeux Ubisoft par la critique et les joueurs, nous avons scrut√© Metacritic, plateforme de r√©f√©rence dans l‚Äôagr√©gation de critiques.<br/>
      Nous avons collect√© les notes et critiques des jeux Ubisoft sortis entre 1995 et 2025, encore une fois √† l‚Äôaide de scraping automatis√© via BeautifulSoup et Selenium.<br/>
      Cette phase a abouti √† la cr√©ation de deux jeux de donn√©es compl√©mentaires, l‚Äôun centr√© sur les notes, l‚Äôautre sur les commentaires qualitatifs.<br/>
      <em>Source : Site Metacritic :</em><br/>
      <a href="https://www.metacritic.com/browse/game/?releaseYearMin=1995&releaseYearMax=2025&page=1">https://www.metacritic.com/browse/game/?releaseYearMin=1995&amp;releaseYearMax=2025&amp;page=1</a>
      </p>
    </div>
    """,
    unsafe_allow_html=True
)








