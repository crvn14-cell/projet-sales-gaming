import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
from pathlib import Path
import unicodedata
import numpy as np
import re

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# APP STREAMLIT : DOSSIER UBISOFT
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="Dossier Ubisoft", page_icon="ğŸ®", layout="wide")

# ğŸ”§ 1) Ajoute "Conclusion" Ã  la navigation (mets Ã  jour ta liste existante)
page = st.sidebar.radio(
    "Aller vers :",
    [
        "Introduction",
        "Analyse financiÃ¨re comparative",
        "Analyse des performances des jeux Ubisoft",
        "Perception et critique : la rupture avec les joueurs",
        "Conclusion",  # â† ajoute cette ligne
    ]
)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Helpers communs
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def strip_accents(s: str) -> str:
    return ''.join(c for c in unicodedata.normalize('NFKD', str(s)) if not unicodedata.combining(c))

def norm_col(c: str) -> str:
    c = strip_accents(str(c)).lower().strip()
    c = re.sub(r'[\s\-_\/]+', ' ', c)
    return c

def clean_numeric(x):
    """Convertit vers float en nettoyant espaces/insÃ©cables/virgules/texte ; NaN -> 0."""
    if pd.isna(x):
        return 0.0
    s = str(x).strip()
    if s in {"", "-", "NA", "N/A", "na", "n/a", "None", "null"}:
        return 0.0
    s = (s.replace('\u202f', '')
           .replace('\xa0', '')
           .replace(' ', '')
           .replace(',', '.'))
    try:
        return float(s)
    except Exception:
        return 0.0

# Chargement unique du CSV global pour toutes les pages
@st.cache_data
def load_finance_data():
    fname = "Finance_Finale.csv"
    candidates = [
        dict(sep=",", encoding="utf-8"),
        dict(sep=";", encoding="utf-8"),
        dict(sep=",", encoding="utf-8-sig"),
        dict(sep=";", encoding="utf-8-sig"),
        dict(sep=",", encoding="cp1252"),
        dict(sep=";", encoding="cp1252"),
    ]
    last_err = None
    for opt in candidates:
        try:
            df = pd.read_csv(fname, **opt, engine="python")
            if df.shape[1] >= 2:
                return df
        except Exception as e:
            last_err = e
            continue
    raise RuntimeError(f"Impossible de lire {fname} : {last_err}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PAGE 1 : INTRODUCTION
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if page == "Introduction":
    st.image("imaubi.png", use_container_width=True)
    st.markdown(
    "<h1 style='text-align: center; color: #1E90FF;'>Ã‰tude sur le phÃ©nomÃ¨ne Ubisoft</h1>",
    unsafe_allow_html=True
)

# Ajout du texte de prÃ©introduction
    st.markdown(
    """
    <div style="text-align: justify; font-size: 18px; line-height: 1.6;">
        Ce projet a pour objectif <strong>dâ€™Ã©tudier le phÃ©nomÃ¨ne Ubisoft</strong>, 
        dâ€™analyser son Ã©volution, et dâ€™explorer les raisons qui pourraient expliquer 
        <strong>sa potentielle chute dans les prochaines annÃ©es</strong>. 
        Nous tenterons de comprendre comment une entreprise autrefois au sommet de 
        lâ€™innovation se retrouve aujourdâ€™hui face Ã  de nouveaux dÃ©fis dans un marchÃ© 
        vidÃ©oludique en constante mutation.
    </div>
    """,
        unsafe_allow_html=True
)
    
    st.title(" ğŸ® Ubisoft â€” Introduction")
   
    introduction = """
    Ubisoft est lâ€™un des plus grands Ã©diteurs de jeux vidÃ©o au monde, reconnu pour ses franchises emblÃ©matiques telles que *Assassin's Creed*, *Far Cry*, *Just Dance*, *Rainbow Six* ou encore *The Division*. FondÃ©e en 1986 par les frÃ¨res Guillemot, lâ€™entreprise a longtemps incarnÃ© le savoir-faire vidÃ©oludique franÃ§ais. Introduite en Bourse en 1996, Ubisoft connaÃ®t une croissance spectaculaire pendant plus de deux dÃ©cennies, atteignant un sommet historique en 2018 avec une action valorisÃ©e Ã  plus de **100 â‚¬**.

    Depuis ce pic, Ubisoft semble enchaÃ®ner les difficultÃ©s. En **2024**, sa capitalisation boursiÃ¨re a chutÃ© de plus de **6 milliards dâ€™euros**, une dÃ©gringolade qui suscite de nombreuses interrogations. Est-elle le reflet dâ€™une crise sectorielle gÃ©nÃ©ralisÃ©e ? Est-elle symptomatique de difficultÃ©s internes Ã  lâ€™entreprise ?

    Ã€ travers ce projet de *data analyse*, notre objectif est de comprendre les facteurs internes ayant contribuÃ© Ã  ce dÃ©clin, en collectant des donnÃ©es financiÃ¨res, critiques et comportementales. Nous chercherons Ã©galement Ã  identifier les signaux faibles et les ruptures stratÃ©giques pouvant expliquer cette trajectoire descendante, tout en proposant des pistes dâ€™amÃ©lioration.
    """
    st.markdown(introduction)
    st.divider()
    
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PAGE 2 : ANALYSE FINANCIÃˆRE COMPARATIVE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
elif page == "Analyse financiÃ¨re comparative":
    st.title(" ğŸ“Š Analyse FinanciÃ¨re Comparative")
    st.caption("Ã‰volution historique, comparaison avec le secteur et analyse des tendances.")

    try:
        df_finance = load_finance_data()
    except Exception as e:
        st.error(f"âš ï¸ Chargement CSV Ã©chouÃ© : {e}")
        st.stop()

   
    # â”€â”€ PARTIE 1 : Historique Ubisoft (texte + image locale)
    st.markdown("""
    ## 1. Analyse financiÃ¨re comparative  
    ### Une trajectoire spectaculaire puis un effondrement brutalâ€¦

    Lâ€™action **Ubisoft** a connu une Ã©volution remarquable depuis son introduction en Bourse le **1er juillet 1996**. DÃ¨s le premier jour de cotation, le titre est multipliÃ© par **252**, portÃ© par lâ€™engouement pour lâ€™industrie vidÃ©oludique et une forte levÃ©e de fonds.  
    Cette dynamique sâ€™est poursuivie pendant plus dâ€™une dÃ©cennie, atteignant un **pic historique de plus de 100 â‚¬ en juillet 2018**. Cette valorisation exceptionnelle reflÃ¨te alors la soliditÃ© des franchises dâ€™Ubisoft, telles que *Assassinâ€™s Creed*, *Far Cry*, *Rainbow Six Siege* et *The Division*, ainsi que la stratÃ©gie de lâ€™Ã©diteur axÃ©e sur les **jeux Ã  monde ouvert** et Ã  fort contenu **solo/multijoueur**.  
    Entre **2014 et 2018**, les rÃ©sultats financiers sont en nette progression, avec un chiffre dâ€™affaires passant de **1,4** Ã  **2,2 milliards de dollars** et une amÃ©lioration significative des marges. Ã€ cette pÃ©riode, **Tencent** entre au capital, consolidant lâ€™image dâ€™Ubisoft comme acteur stratÃ©gique Ã  lâ€™international.  
    Pourtant, dÃ¨s **2019**, les rÃ©sultats commencent Ã  dÃ©cevoir : plusieurs jeux ne rÃ©pondent pas aux attentes, les retards sâ€™accumulent, et la rentabilitÃ© sâ€™effrite. Le titre entame alors une **chute prolongÃ©e** : en **cinq ans**, lâ€™action perd plus de **80 % de sa valeur**. Depuis 2018, cela reprÃ©sente une **perte de capitalisation boursiÃ¨re dâ€™environ 9 milliards dâ€™euros**.
    """)

        # â”€â”€ PARTIE 1 : Historique Ubisoft (chargement auto de l'image)
    st.subheader(" Ã‰volution historique du cours de lâ€™action Ubisoft")

    @st.cache_data(show_spinner=False)
    def _find_ubisoft_chart() -> str | None:
        base = Path(__file__).parent
        # chemins les plus probables (mets l'image Ã  la racine ou dans assets/images/static)
        candidates = [
            base / "ubisoft_google_finance.png",
            base / "assets" / "ubisoft_google_finance.png",
            base / "images" / "ubisoft_google_finance.png",
            base / "static" / "ubisoft_google_finance.png",
            base / "Capture d'Ã©cran 2025-08-25 141139.png",
            base / "assets" / "Capture d'Ã©cran 2025-08-25 141139.png",
            base / "images" / "Capture d'Ã©cran 2025-08-25 141139.png",
            base / "static" / "Capture d'Ã©cran 2025-08-25 141139.png",
        ]
        for p in candidates:
            if p.exists():
                return str(p)
        # recherche de secours par motif
        for folder in [base, base / "assets", base / "images", base / "static"]:
            for pat in ("ubisoft*finance*.*", "Ubisoft*Finance*.*", "Capture d'Ã©cran 2025-08-25 141139.*"):
                for p in folder.glob(pat):
                    return str(p)
        return None

    img_path = _find_ubisoft_chart()

    if img_path:
        st.image(
            img_path,
            caption="Ã‰volution historique du cours Ubisoft â€” Source : Google Finance (EPA : UBI)",
            use_container_width=True
        )
    else:
        st.error(
            "Image introuvable. Place le fichier **ubisoft_google_finance.png** "
            "ou **Capture d'Ã©cran 2025-08-25 141139.png** Ã  la racine du projet "
            "ou dans **./assets/**, **./images/** ou **./static/**."
        )

    st.divider()

    # â”€â”€ PARTIE 2 : Performance relative au secteur (texte + courbes comparatives)
    st.markdown("""
    ## 2. Une performance financiÃ¨re en retrait

    Pour mieux comprendre le contexte du dÃ©clin dâ€™Ubisoft, nous avons comparÃ© lâ€™Ã©volution de son cours de Bourse Ã  celle des deux principaux **ETF sectoriels** dÃ©diÃ©s au jeu vidÃ©o : **ESPO** (*VanEck Video Gaming & eSports*) et **HERO** (*Global X Video Games & Esports ETF*). Ces deux indices regroupent les plus grands Ã©diteurs mondiaux du secteur.

    Lâ€™analyse sur les **cinq derniÃ¨res annÃ©es** met en Ã©vidence une **divergence nette**. Si les trois courbes suivent une trajectoire globalement similaire jusquâ€™en **2022** â€” marquÃ©e par une baisse partagÃ©e â€”, les dynamiques sâ€™opposent par la suite : **ESPO** repart Ã  la hausse dÃ¨s **2023**, amorÃ§ant une phase de croissance continue, tandis quâ€™**Ubisoft** poursuit son repli, atteignant mÃªme un **point bas autour de 10 â‚¬ en 2024**.

    Cette dissociation entre lâ€™Ã©volution du marchÃ© global et celle dâ€™Ubisoft confirme que **le problÃ¨me semble spÃ©cifique Ã  lâ€™entreprise**. La performance boursiÃ¨re dâ€™Ubisoft ne peut pas Ãªtre attribuÃ©e Ã  une crise sectorielle : au contraire, lâ€™industrie du jeu vidÃ©o **continue de progresser dans son ensemble**. Cela renforce lâ€™hypothÃ¨se dâ€™une **crise interne** â€” un axe que nous tenterons dâ€™explorer dans les chapitres suivants.
    """)

    st.subheader(" Comparaison Ubisoft vs ETF ESPO & HERO")
    df_etf = pd.DataFrame({
        "AnnÃ©e":   [2020, 2021, 2022, 2023, 2024],
        "Ubisoft": [85,   75,   50,   25,   10],
        "ESPO":    [100,  110,  90,   120,  140],
        "HERO":    [95,   105,  85,   115,  135],
    })
    fig2, ax2 = plt.subplots(figsize=(10, 6))
    ax2.plot(df_etf["AnnÃ©e"], df_etf["Ubisoft"], marker="o", color="red",   label="Ubisoft")
    ax2.plot(df_etf["AnnÃ©e"], df_etf["ESPO"],    marker="o", color="green", label="ESPO")
    ax2.plot(df_etf["AnnÃ©e"], df_etf["HERO"],    marker="o", color="blue",  label="HERO")
    ax2.set_title("Ã‰volution du cours Ubisoft vs ESPO & HERO (5 derniÃ¨res annÃ©es)", fontsize=14)
    ax2.set_xlabel("AnnÃ©e"); ax2.set_ylabel("Valeur normalisÃ©e (base 100)")
    ax2.grid(True, linestyle="--", alpha=0.6); ax2.legend()
    ax2.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))
    st.pyplot(fig2)
    st.divider()

    # â”€â”€ PARTIE 3 : CA cumulÃ© par Ã©diteur (lecture robuste depuis df_finance)
    st.markdown("""
    **Observation complÃ©mentaire.**  
    Sur la pÃ©riode Ã©tudiÃ©e, le **chiffre dâ€™affaires cumulÃ©** dâ€™Ubisoft est **le plus faible parmi les Ã©diteurs majeurs du secteur**. 
    """)
    st.subheader(" Chiffre dâ€™affaires cumulÃ© par Ã©diteur (2018â€“2024) ")

    raw = df_finance.copy()
    norm_map = {c: norm_col(c) for c in raw.columns}
    df = raw.rename(columns=norm_map)

    cumu_alias = [
        'ca cumule (mâ‚¬)','ca cumule','chiffre daffaires cumule (mâ‚¬)',
        'chiffre daffaires cumule','revenue cumule (mâ‚¬)','revenu cumule (mâ‚¬)','revenue total (mâ‚¬)'
    ]
    year_cols_cols = [c for c in df.columns if re.fullmatch(r'(?:fy)?(20(1[8-9]|2[0-4]))', c)]
    if not year_cols_cols:
        year_cols_cols = [c for c in df.columns if re.search(r'20(1[8-9]|2[0-4])', c)]
    year_line_alias = ['annee','year','date']
    editor_alias = ['editeur','Ã©diteur','publisher','societe','entreprise','company','studio','nom','compagnie']
    editor_col = next((c for c in df.columns if c in editor_alias), None)
    if editor_col is None:
        for c in df.columns:
            if df[c].dtype == object:
                editor_col = c; break
    if editor_col is None:
        st.error("Colonne 'Editeur' introuvable dans Finance_Finale.csv"); st.stop()

    cumu_col = next((c for c in df.columns if c in cumu_alias), None)
    if cumu_col:
        out = pd.DataFrame({
            "Ã‰diteur": df[editor_col],
            "CA cumulÃ© (Mâ‚¬)": df[cumu_col].apply(clean_numeric)
        })
    elif year_cols_cols:
        tmp = df[[editor_col] + year_cols_cols].copy()
        for c in year_cols_cols:
            tmp[c] = tmp[c].apply(clean_numeric)
        total = tmp[year_cols_cols].sum(axis=1)
        if pd.notna(total.max()) and total.max() > 1_000_000:
            total = total / 1_000_000.0
        out = pd.DataFrame({"Ã‰diteur": tmp[editor_col], "CA cumulÃ© (Mâ‚¬)": total})
    else:
        annee_col = next((c for c in df.columns if c in year_line_alias or "annee" in c or "year" in c or "date" in c), None)
        ca_candidates = [c for c in df.columns if any(k in c for k in ['chiffre','revenue','revenu','sales','ca '])]
        ca_col = ca_candidates[0] if ca_candidates else None
        if not (annee_col and ca_col):
            st.error("Colonnes nÃ©cessaires non trouvÃ©es (AnnÃ©e + Chiffre d'affaires)."); st.stop()
        work = df[[editor_col, annee_col, ca_col]].copy()
        work['__year__'] = pd.to_datetime(work[annee_col], errors='coerce').dt.year
        work['__ca__'] = work[ca_col].apply(clean_numeric)
        mask = work['__year__'].between(2018, 2024, inclusive='both')
        grouped = (work[mask].groupby(editor_col, as_index=False)['__ca__'].sum()
                   .rename(columns={editor_col:"Ã‰diteur", '__ca__':"CA cumulÃ© (Mâ‚¬)"}))
        out = grouped
        if pd.notna(out["CA cumulÃ© (Mâ‚¬)"].max()) and out["CA cumulÃ© (Mâ‚¬)"].max() > 1_000_000:
            out["CA cumulÃ© (Mâ‚¬)"] = out["CA cumulÃ© (Mâ‚¬)"] / 1_000_000.0

    out = out.dropna(subset=["Ã‰diteur"]).copy()
    out["CA cumulÃ© (Mâ‚¬)"] = pd.to_numeric(out["CA cumulÃ© (Mâ‚¬)"], errors='coerce').fillna(0)
    out = out.sort_values("CA cumulÃ© (Mâ‚¬)", ascending=False)

    fig3, ax3 = plt.subplots(figsize=(10, 6))
    bars = ax3.bar(out["Ã‰diteur"], out["CA cumulÃ© (Mâ‚¬)"])
    ax3.set_title("Chiffre d'affaires cumulÃ© par Ã©diteur de 2018 Ã  2024", fontsize=14)
    ax3.set_xlabel("Ã‰diteurs"); ax3.set_ylabel("Chiffre d'affaires cumulÃ© (Mâ‚¬)")
    ax3.grid(axis="y", linestyle="--", alpha=0.5)
    plt.xticks(rotation=45, ha="right")
    for b, v in zip(bars, out["CA cumulÃ© (Mâ‚¬)"]):
        ax3.annotate(f"{int(round(v)):,}".replace(",", " "),
                     xy=(b.get_x() + b.get_width()/2, v),
                     xytext=(0, 5), textcoords="offset points",
                     ha="center", va="bottom", fontsize=9)
    st.pyplot(fig3)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Graphiques comparatifs CA, RÃ©sultat net, Masse salariale (interactifs)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.divider()
    st.markdown("""
    Plus prÃ©occupant encore, **le chiffre dâ€™affaires dâ€™Ubisoft nâ€™Ã©volue quasiment pas**, alors que la majoritÃ© des **concurrents** (*Sony Interactive Entertainment, Electronic Arts, Bandai Namco*, etc.) affichent **une croissance continue**.  
    Cette **stagnation** est un **signal dâ€™alerte fort**, dâ€™autant plus que le **marchÃ© global du jeu vidÃ©o** est, lui, **en croissance**.
    """)
    st.subheader("Ã‰volution du chiffre dâ€™affaires (2018â€“2024) ")

    def _to_long(df_in: pd.DataFrame) -> pd.DataFrame:
        df = df_in.rename(columns={c: unicodedata.normalize("NFKD", str(c)).encode("ascii","ignore").decode().strip().lower()
                                   for c in df_in.columns})
        year_cols = [c for c in df.columns if re.fullmatch(r'(?:fy)?(20(1[8-9]|2[0-4]))', c)]
        if not year_cols:
            year_cols = [c for c in df.columns if re.search(r'20(1[8-9]|2[0-4])', c)]
        ed_col = next((c for c in df.columns if c in
                       ["editeur","publisher","entreprise","societe","company","studio","nom","compagnie"]), None)
        if ed_col is None:
            for c in df.columns:
                if df[c].dtype == object:
                    ed_col = c; break
        if ed_col is None:
            raise ValueError("Colonne Ã©diteur introuvable.")

        if year_cols:
            long = df[[ed_col] + year_cols].copy().melt(id_vars=[ed_col], var_name="annee", value_name="valeur")
            long["annee"] = long["annee"].astype(str).str.extract(r'(20\d{2})').astype(int)
            long["valeur"] = long["valeur"].apply(clean_numeric)
            long = long.rename(columns={ed_col:"Editeur"})
            return long

        an_col = next((c for c in df.columns if c in ["annee","year","date"] or "annee" in c or "year" in c or "date" in c), None)
        val_col = next((c for c in df.columns if any(k in c for k in ["chiffre","revenue","revenu","sales","ca"])), None)
        if an_col is None or val_col is None:
            raise ValueError("Colonnes requises non trouvÃ©es (AnnÃ©e + CA).")
        long = df[[ed_col, an_col, val_col]].copy().rename(columns={ed_col:"Editeur", an_col:"annee", val_col:"valeur"})
        long["annee"] = pd.to_datetime(long["annee"], errors="coerce").dt.year
        long["valeur"] = long["valeur"].apply(clean_numeric)
        return long

    df_multi_raw = df_finance.copy()
    data_long = _to_long(df_multi_raw)
    data_long = data_long.dropna(subset=["Editeur","annee"])
    data_long = data_long[(data_long["annee"]>=2018) & (data_long["annee"]<=2024)]
    data_long["valeur"] = data_long["valeur"].apply(clean_numeric)

    editeurs_dispos = sorted(data_long["Editeur"].unique().tolist())
    col_a, col_b = st.columns([2,1])
    with col_a:
        sel_editeurs = st.multiselect("Ã‰diteurs Ã  afficher :", editeurs_dispos, default=editeurs_dispos)
    with col_b:
        years_min, years_max = int(data_long["annee"].min()), int(data_long["annee"].max())
        an_range = st.slider("Plage dâ€™annÃ©es :", min_value=years_min, max_value=years_max, value=(2018, 2024), step=1)

    dfp = data_long[(data_long["Editeur"].isin(sel_editeurs)) &
                    (data_long["annee"].between(an_range[0], an_range[1]))].copy()
    full_index = pd.MultiIndex.from_product([sorted(set(sel_editeurs)), list(range(an_range[0], an_range[1]+1))],
                                            names=["Editeur", "annee"])
    dfp = (dfp.groupby(["Editeur", "annee"], as_index=False)["valeur"].sum()
              .set_index(["Editeur","annee"])
              .reindex(full_index)
              .fillna(0.0)
              .reset_index())

    if dfp.empty:
        st.warning("Aucune donnÃ©e pour la sÃ©lection actuelle.")
    else:
        annees = sorted(dfp["annee"].unique().tolist())
        publishers = sel_editeurs
        n_pub = len(publishers)
        total_width = 0.8
        bar_width = total_width / max(n_pub,1)
        x = list(range(len(annees)))
        fig, ax = plt.subplots(figsize=(10,6))
        for i, pub in enumerate(publishers):
            y_vals = [float(dfp[(dfp["Editeur"]==pub) & (dfp["annee"]==a)]["valeur"].sum()) for a in annees]
            offsets = [xx + (i - (n_pub-1)/2)*bar_width for xx in x]
            ax.bar(offsets, y_vals, width=bar_width, label=pub)
        ax.set_xticks(x); ax.set_xticklabels(annees, rotation=0)
        ax.set_title("Ã‰volution du chiffre dâ€™affaires (Mâ‚¬) par Ã©diteur", fontsize=14)
        ax.set_xlabel("AnnÃ©e"); ax.set_ylabel("Chiffre d'affaires (Mâ‚¬)")
        ax.grid(axis="y", linestyle="--", alpha=0.5)
        ax.legend(ncol=2, fontsize=9)
        st.pyplot(fig)

    # RÃ©sultat net â€” similaire
    st.divider()
    st.markdown("""
    **Le rÃ©sultat net cumulÃ© dâ€™Ubisoft est en net retrait par rapport Ã  ses pairs**, alors que la majoritÃ© de ses concurrents restent **bÃ©nÃ©ficiaires** sur la mÃªme pÃ©riode.  
    Ce **dÃ©ficit chronique** montre quâ€™Ubisoft ne parvient pas Ã  **transformer ses ventes en valeur** pour ses actionnaires, et que sa **structure de coÃ»ts** nâ€™est pas suffisamment maÃ®trisÃ©e.
    """)
    st.subheader(" RÃ©sultat net (Mâ‚¬) â€” Ã©volution 2018â€“2024")

    def to_long_metric(df_in: pd.DataFrame, metric_keywords) -> pd.DataFrame:
        df = df_in.rename(columns={c: norm_col(c) for c in df_in.columns})
        year_cols = [c for c in df.columns if re.fullmatch(r'(?:fy)?(20(1[8-9]|2[0-4]))', c)]
        if not year_cols:
            year_cols = [c for c in df.columns if re.search(r'20(1[8-9]|2[0-4])', c)]
        ed_col = next((c for c in df.columns if c in
                       ["editeur","Ã©diteur","publisher","entreprise","societe","company","studio","nom","compagnie"]), None)
        if ed_col is None:
            for c in df.columns:
                if df[c].dtype == object:
                    ed_col = c; break
        if ed_col is None:
            raise ValueError("Colonne Ã©diteur introuvable.")
        if year_cols:
            long = df[[ed_col] + year_cols].copy().melt(id_vars=[ed_col], var_name="annee", value_name="valeur")
            long["annee"] = long["annee"].astype(str).str.extract(r'(20\d{2})').astype(int)
            long["valeur"] = long["valeur"].apply(clean_numeric)
            long = long.rename(columns={ed_col: "Editeur"})
            return long
        an_col = next((c for c in df.columns if c in ["annee","year","date"] or "annee" in c or "year" in c or "date" in c), None)
        val_col = next((c for c in df.columns if any(k in c for k in metric_keywords)), None)
        if an_col is None or val_col is None:
            raise ValueError("Colonnes requises non trouvÃ©es (AnnÃ©e + RÃ©sultat net).")
        long = df[[ed_col, an_col, val_col]].copy().rename(columns={ed_col:"Editeur", an_col:"annee", val_col:"valeur"})
        long["annee"] = pd.to_datetime(long["annee"], errors="coerce").dt.year
        long["valeur"] = long["valeur"].apply(clean_numeric)
        return long

    data_profit = to_long_metric(df_finance.copy(), ["resultat","rÃ©sultat","net income","profit","benefice","bÃ©nÃ©fice"])
    data_profit = data_profit.dropna(subset=["Editeur","annee"])
    data_profit = data_profit[(data_profit["annee"]>=2018) & (data_profit["annee"]<=2024)]
    data_profit["valeur"] = data_profit["valeur"].apply(clean_numeric)

    editeurs_p = sorted(data_profit["Editeur"].unique().tolist())
    col1, col2 = st.columns([2,1])
    with col1:
        sel_ed_p = st.multiselect("Ã‰diteurs Ã  afficher :", editeurs_p, default=editeurs_p, key="prof_ed")
    with col2:
        y_min, y_max = int(data_profit["annee"].min()), int(data_profit["annee"].max())
        an_range_p = st.slider("Plage dâ€™annÃ©es :", min_value=y_min, max_value=y_max, value=(2018, 2024), step=1, key="prof_year")

    dfp_p = data_profit[(data_profit["Editeur"].isin(sel_ed_p)) &
                        (data_profit["annee"].between(an_range_p[0], an_range_p[1]))].copy()
    idx_full = pd.MultiIndex.from_product([sorted(set(sel_ed_p)), list(range(an_range_p[0], an_range_p[1]+1))],
                                          names=["Editeur","annee"])
    dfp_p = (dfp_p.groupby(["Editeur","annee"], as_index=False)["valeur"].sum()
                .set_index(["Editeur","annee"])
                .reindex(idx_full)
                .fillna(0.0)
                .reset_index())

    if dfp_p.empty:
        st.warning("Aucune donnÃ©e pour la sÃ©lection actuelle.")
    else:
        annees_p = sorted(dfp_p["annee"].unique().tolist())
        pubs_p = sel_ed_p; n_pub_p = len(pubs_p)
        total_w = 0.8; bw = total_w / max(n_pub_p,1); x = list(range(len(annees_p)))
        figp, axp = plt.subplots(figsize=(10,6))
        for i, pub in enumerate(pubs_p):
            yv = [float(dfp_p[(dfp_p["Editeur"]==pub) & (dfp_p["annee"]==a)]["valeur"].sum()) for a in annees_p]
            offs = [xx + (i - (n_pub_p-1)/2)*bw for xx in x]
            axp.bar(offs, yv, width=bw, label=pub)
        axp.axhline(0, color="black", linewidth=1)
        axp.set_xticks(x); axp.set_xticklabels(annees_p, rotation=0)
        axp.set_title("RÃ©sultat net (Mâ‚¬) par Ã©diteur", fontsize=14)
        axp.set_xlabel("AnnÃ©e"); axp.set_ylabel("RÃ©sultat net (Mâ‚¬)")
        axp.grid(axis="y", linestyle="--", alpha=0.5)
        axp.legend(ncol=2, fontsize=9)
        st.pyplot(figp)

    # Masse salariale
    st.divider()
    st.markdown("""
    Lâ€™un des Ã©carts les plus marquants est observÃ© au niveau de la **masse salariale**.  
    **Ubisoft** emploie un volume de salariÃ©s **comparable** Ã  celui dâ€™**Activision Blizzard**, mais ses **performances financiÃ¨res** sont nettement **infÃ©rieures**.  
    Par exemple, **Electronic Arts** opÃ¨re avec **environ un tiers de personnel en moins**, tout en gÃ©nÃ©rant un **chiffre dâ€™affaires** et un **rÃ©sultat net** largement supÃ©rieurs.
    """)
    st.subheader(" Masse salariale (Mâ‚¬) â€” Ã©volution 2018â€“2024")

    def _to_long_payroll(df_in: pd.DataFrame) -> pd.DataFrame:
        df = df_in.rename(columns={c: norm_col(c) for c in df_in.columns})
        year_cols = [c for c in df.columns if re.fullmatch(r'(?:fy)?(20(1[8-9]|2[0-4]))', c)]
        if not year_cols:
            year_cols = [c for c in df.columns if re.search(r'20(1[8-9]|2[0-4])', c)]
        ed_col = next((c for c in df.columns if c in
                      ["editeur","Ã©diteur","publisher","entreprise","societe","company","studio","nom","compagnie"]), None)
        if ed_col is None:
            for c in df.columns:
                if df[c].dtype == object:
                    ed_col = c; break
        if ed_col is None:
            raise ValueError("Colonne Ã©diteur introuvable.")
        if year_cols:
            long = df[[ed_col] + year_cols].copy().melt(id_vars=[ed_col], var_name="annee", value_name="valeur")
            long["annee"] = long["annee"].astype(str).str.extract(r'(20\d{2})').astype(int)
            long["valeur"] = long["valeur"].apply(clean_numeric)
            long = long.rename(columns={ed_col:"Editeur"})
            return long
        an_col = next((c for c in df.columns if c in ["annee","year","date"] or "annee" in c or "year" in c or "date" in c), None)
        val_col = next((c for c in df.columns if any(k in c for k in
                   ["masse salariale","payroll","personnel","staff cost","wages","salaires","salary","coÃ»t du personnel","cout du personnel"])), None)
        if an_col is None or val_col is None:
            raise ValueError("Colonnes requises non trouvÃ©es (AnnÃ©e + Masse salariale).")
        long = df[[ed_col, an_col, val_col]].copy().rename(columns={ed_col:"Editeur", an_col:"annee", val_col:"valeur"})
        long["annee"] = pd.to_datetime(long["annee"], errors="coerce").dt.year
        long["valeur"] = long["valeur"].apply(clean_numeric)
        return long

    payroll_long = _to_long_payroll(df_finance.copy())
    payroll_long = payroll_long.dropna(subset=["Editeur","annee"])
    payroll_long = payroll_long[(payroll_long["annee"]>=2018) & (payroll_long["annee"]<=2024)]
    payroll_long["valeur"] = payroll_long["valeur"].apply(clean_numeric)

    editeurs_pay = sorted(payroll_long["Editeur"].unique().tolist())
    c1, c2 = st.columns([2,1])
    with c1:
        sel_editeurs_pay = st.multiselect("Ã‰diteurs Ã  afficher :", editeurs_pay, default=editeurs_pay, key="pay_ed")
    with c2:
        y_min_p, y_max_p = int(payroll_long["annee"].min()), int(payroll_long["annee"].max())
        an_range_pay = st.slider("Plage dâ€™annÃ©es :", min_value=y_min_p, max_value=y_max_p, value=(2018, 2024), step=1, key="pay_year")

    dfp_pay = payroll_long[(payroll_long["Editeur"].isin(sel_editeurs_pay)) &
                           (payroll_long["annee"].between(an_range_pay[0], an_range_pay[1]))].copy()
    full_idx_pay = pd.MultiIndex.from_product([sorted(set(sel_editeurs_pay)),
                                               list(range(an_range_pay[0], an_range_pay[1]+1))],
                                              names=["Editeur","annee"])
    dfp_pay = (dfp_pay.groupby(["Editeur","annee"], as_index=False)["valeur"].sum()
                    .set_index(["Editeur","annee"])
                    .reindex(full_idx_pay)
                    .fillna(0.0)
                    .reset_index())

    if dfp_pay.empty:
        st.warning("Aucune donnÃ©e pour la sÃ©lection actuelle (masse salariale).")
    else:
        annees_pay = sorted(dfp_pay["annee"].unique().tolist())
        pubs_pay = sel_editeurs_pay
        n_pub_pay = len(pubs_pay)
        total_w = 0.8; bw = total_w / max(n_pub_pay,1); x = list(range(len(annees_pay)))
        figp2, axp2 = plt.subplots(figsize=(10,6))
        for i, pub in enumerate(pubs_pay):
            y_vals = [float(dfp_pay[(dfp_pay["Editeur"]==pub) & (dfp_pay["annee"]==a)]["valeur"].sum()) for a in annees_pay]
            offs = [xx + (i - (n_pub_pay-1)/2)*bw for xx in x]
            axp2.bar(offs, y_vals, width=bw, label=pub)
        axp2.set_xticks(x); axp2.set_xticklabels(annees_pay, rotation=0)
        axp2.set_title("Ã‰volution de la masse salariale (Mâ‚¬) par Ã©diteur", fontsize=14)
        axp2.set_xlabel("AnnÃ©e"); axp2.set_ylabel("Masse salariale (Mâ‚¬)")
        axp2.grid(axis="y", linestyle="--", alpha=0.5)
        axp2.legend(ncol=2, fontsize=9)
        st.pyplot(figp2)

    # Bulles : CAâ†”RÃ©sultat (taille = masse salariale) + Masse salariale â†” Effectif
    st.divider()
    st.subheader(" RÃ©sultat net vs Chiffre dâ€™affaires ")
    st.caption("Les deux graphiques ci-dessous utilisent les mÃªmes donnÃ©es centralisÃ©es.")

    def _normalize_columns_for_panel(df_in: pd.DataFrame) -> pd.DataFrame:
        df = df_in.rename(columns={c: norm_col(c) for c in df_in.columns})
        ed_col = next((c for c in df.columns if c in
                       ["editeur","Ã©diteur","publisher","entreprise","societe","company","studio","nom","compagnie"]), None)
        if ed_col is None:
            for c in df.columns:
                if df[c].dtype == object:
                    ed_col = c; break
        if ed_col is None:
            raise ValueError("Colonne Ã©diteur introuvable.")
        KEYWORDS = {
            "ca": ["chiffre","sales","revenue","revenu","ca"],
            "profit": ["resultat","rÃ©sultat","net income","profit","benefice","bÃ©nÃ©fice"],
            "payroll": ["masse salariale","payroll","personnel","staff cost","wages","salaires","salary","coÃ»t du personnel","cout du personnel"],
            "headcount": ["effectif","headcount","employe","employee","staff"]
        }
        def find_col(dfcols, words):
            return next((c for c in dfcols if any(w in c for w in words)), None)

        an_col = next((c for c in df.columns if c in ["annee","year","date"] or "annee" in c or "year" in c or "date" in c), None)
        ca_col      = find_col(df.columns, KEYWORDS["ca"])
        profit_col  = find_col(df.columns, KEYWORDS["profit"])
        payroll_col = find_col(df.columns, KEYWORDS["payroll"])
        headc_col   = find_col(df.columns, KEYWORDS["headcount"])

        panel = pd.DataFrame({"Editeur": df[ed_col]})
        if an_col is not None:
            panel["annee"] = pd.to_datetime(df[an_col], errors="coerce").dt.year
        else:
            panel["annee"] = np.nan

        if ca_col:      panel["ca"]       = df[ca_col].apply(clean_numeric)
        if profit_col:  panel["profit"]   = df[profit_col].apply(clean_numeric)
        if payroll_col: panel["payroll"]  = df[payroll_col].apply(clean_numeric)
        if headc_col:   panel["headcount"]= df[headc_col].apply(clean_numeric)
        for col in ["ca","profit","payroll","headcount"]:
            if col not in panel.columns:
                panel[col] = 0.0
        return panel

    panel = _normalize_columns_for_panel(df_finance.copy())
    panel = panel.dropna(subset=["Editeur"])
    if panel["annee"].notna().any():
        panel = panel[(panel["annee"].between(2018, 2024, inclusive="both")) | panel["annee"].isna()].copy()
    for c in ["ca","profit","payroll","headcount"]:
        panel[c] = panel[c].apply(clean_numeric)

    colsA, colsB, colsC = st.columns([2,1,1])
    with colsA:
        editeurs_sel = st.multiselect("Ã‰diteurs :", sorted(panel["Editeur"].unique()),
                                      default=sorted(panel["Editeur"].unique()))
    with colsB:
        if panel["annee"].notna().any():
            y_min2, y_max2 = int(panel["annee"].min()), int(panel["annee"].max())
            an_range2 = st.slider("AnnÃ©es :", min_value=y_min2, max_value=y_max2, value=(max(2018,y_min2), min(2024,y_max2)), step=1)
        else:
            an_range2 = (2018, 2024)
    with colsC:
        size_scale = st.slider("Ã‰chelle des bulles (masse salariale)", 0.1, 2.0, 0.7, 0.1)
        alpha_pts  = st.slider("Transparence", 0.2, 1.0, 0.8, 0.1)

    if panel["annee"].notna().any():
        dfp_panel = panel[(panel["Editeur"].isin(editeurs_sel)) &
                          (panel["annee"].between(an_range2[0], an_range2[1]))].copy()
    else:
        dfp_panel = panel[panel["Editeur"].isin(editeurs_sel)].copy()

    if dfp_panel.empty:
        st.warning("Aucune donnÃ©e pour la sÃ©lection actuelle.")
    else:
        fig_b, ax_b = plt.subplots(figsize=(9.5, 6.5))
        for ed in sorted(dfp_panel["Editeur"].unique()):
            d = dfp_panel[dfp_panel["Editeur"] == ed]
            ax_b.scatter(d["ca"], d["profit"], s=np.sqrt(d["payroll"].clip(lower=0))*(10*size_scale),
                         alpha=alpha_pts, label=ed)
        ax_b.set_title("RÃ©sultat net (Mâ‚¬) en fonction du chiffre dâ€™affaires (Mâ‚¬) â€” taille = masse salariale", fontsize=13)
        ax_b.set_xlabel("Chiffre dâ€™affaires (Mâ‚¬)")
        ax_b.set_ylabel("RÃ©sultat net (Mâ‚¬)")
        ax_b.grid(True, linestyle="--", alpha=0.4)
        ax_b.legend(ncol=2, fontsize=9, frameon=True)
        st.pyplot(fig_b)

        st.subheader(" Masse salariale vs Effectif total (2018â€“2024)")
        fig_c, ax_c = plt.subplots(figsize=(9.5, 6.0))
        for ed in sorted(dfp_panel["Editeur"].unique()):
            d = dfp_panel[dfp_panel["Editeur"] == ed]
            ax_c.scatter(d["headcount"], d["payroll"], alpha=alpha_pts, label=ed)
        ax_c.set_title("CoÃ»t de la masse salariale (Mâ‚¬) en fonction de lâ€™effectif total", fontsize=13)
        ax_c.set_xlabel("Effectif total (personnes)")
        ax_c.set_ylabel("Masse salariale (Mâ‚¬)")
        ax_c.grid(True, linestyle="--", alpha=0.4)
        ax_c.legend(ncol=2, fontsize=9, frameon=True)
        st.pyplot(fig_c)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PAGE 3 : ANALYSE DES PERFORMANCES DES JEUX UBISOFT
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
elif page == "Analyse des performances des jeux Ubisoft":
    st.title("ğŸ¯ Analyse des performances des jeux Ubisoft")
    st.markdown("""
    Au-delÃ  des indicateurs financiers globaux, lâ€™analyse du **catalogue** dâ€™Ubisoft rÃ©vÃ¨le des Ã©lÃ©ments structurants.
    En Ã©tudiant la frÃ©quence des sorties, les revenus par jeu et le volume total de titres publiÃ©s, on observe des tendances claires.
    """)

    st.subheader("2.1. Une stratÃ©gie axÃ©e sur le volume")
    st.markdown("""
    Ubisoft se distingue de ses concurrents par une production particuliÃ¨rement **prolifique** :
    le **nombre de jeux publiÃ©s** chaque annÃ©e est largement supÃ©rieur Ã  la moyenne du secteur.
    Cette stratÃ©gie sâ€™appuie sur une **capacitÃ© de dÃ©veloppement rÃ©partie** sur plusieurs studios dans le monde,
    ainsi que sur des **processus industriels bien rodÃ©s**.
    """)

    # ---------- IMPORTS ----------
    import pandas as pd
    import plotly.express as px
    import plotly.graph_objects as go
    import unicodedata, re

    # ---------- Helpers ----------
    def _norm(s: str) -> str:
        s = unicodedata.normalize("NFKD", str(s))
        s = "".join(c for c in s if not unicodedata.combining(c))
        return re.sub(r"[\s\-_\/]+", " ", s).strip().lower()

    def _to_float(x):
        if pd.isna(x): return 0.0
        s = (str(x).strip()
                .replace("\u202f","").replace("\xa0","")
                .replace(" ", "").replace(",", "."))
        s = re.sub(r"(â‚¬|eur|euros|millions?)$", "", s, flags=re.I)
        try: return float(s)
        except: return 0.0

    def apply_light_theme(fig, *, title_text, x_title, y1_title, y2_title=None):
        layout_kwargs = dict(
            title=dict(text=title_text, x=0.5, xanchor="center",
                       font=dict(size=20, color="#000")),
            plot_bgcolor="white",
            paper_bgcolor="white",
            hovermode="x unified",
            legend=dict(bgcolor="rgba(255,255,255,0.9)", bordercolor="#000", borderwidth=1, font=dict(size=13, color="#111")),
            margin=dict(l=70, r=70, t=70, b=70),
            xaxis=dict(title=x_title, tickfont=dict(size=12, color="#000"),
                       showline=True, linecolor="#000", linewidth=2, showgrid=True, gridcolor="rgba(0,0,0,0.25)"),
            yaxis=dict(title=y1_title, tickfont=dict(size=12, color="#000"),
                       showline=True, linecolor="#000", linewidth=2, showgrid=True, gridcolor="rgba(0,0,0,0.25)"),
            height=460
        )
        if y2_title:
            layout_kwargs["yaxis2"] = dict(
                title=y2_title, overlaying="y", side="right",
                showline=True, linecolor="#000", linewidth=2,
                tickfont=dict(size=12, color="#000")
            )
        fig.update_layout(**layout_kwargs)
        return fig

    def _find_col(dfcols, keywords):
        for c in dfcols:
            if any(k in c for k in keywords):
                return c
        return None

    # ---------- Chargement du CSV Ã©diteurs ----------
    try:
        df_ed = pd.read_csv("editeurs_nettoyÃ©es.csv")
    except Exception as e:
        st.error(f"âš ï¸ Impossible de charger le CSV : {e}")
        st.stop()

    # ---------- VÃ©rification/alignement colonnes ----------
    expected_cols = ["Nom", "Jeux publiÃ©s", "Revenu total (milliards)"]
    for col in expected_cols:
        if col not in df_ed.columns:
            cands = [c for c in df_ed.columns if _norm(c) == _norm(col)]
            if cands:
                df_ed.rename(columns={cands[0]: col}, inplace=True)
            else:
                st.error(f"âš ï¸ Colonne manquante : '{col}' â€” colonnes disponibles : {list(df_ed.columns)}")
                st.stop()

    # ---------- Harmonisation des Ã©diteurs ----------
    mapping_editeurs = {
        "ubisoft": "Ubisoft",
        "electronic arts": "Electronic Arts", "ea": "Electronic Arts",
        "sega": "SEGA",
        "square enix": "Square Enix",
        "bandai": "Bandai Namco", "bandai namco": "Bandai Namco",
        "take two": "Take-Two", "take-two": "Take-Two", "2k": "Take-Two", "2k games": "Take-Two"
    }
    df_ed["Editeur"] = df_ed["Nom"].apply(lambda x: mapping_editeurs.get(_norm(x), None))

    # ---------- Filtrer les 6 Ã©diteurs du projet ----------
    editeurs_cibles = ["Ubisoft", "Electronic Arts", "SEGA", "Square Enix", "Bandai Namco", "Take-Two"]
    dff = df_ed[df_ed["Editeur"].isin(editeurs_cibles)].copy()
    if dff.empty:
        st.error("âš ï¸ Aucune donnÃ©e trouvÃ©e pour les 6 Ã©diteurs attendus.")
        st.write("Ã‰diteurs trouvÃ©s :", sorted(df_ed["Nom"].unique()))
        st.stop()

    # ---------- AgrÃ©gation ----------
    dff = (dff.groupby("Editeur", as_index=False)
              .agg(**{
                  "Jeux publiÃ©s": ("Jeux publiÃ©s", "sum"),
                  "Revenu total (milliards)": ("Revenu total (milliards)", "sum")
              }))

    # ---------- Graphique 1 : Volume vs Revenu total ----------
    dff["Couleur"] = dff["Editeur"].apply(lambda n: "Ubisoft" if n == "Ubisoft" else "Autres")
    fig1 = px.scatter(
        dff,
        x="Jeux publiÃ©s",
        y="Revenu total (milliards)",
        text="Editeur",
        color="Couleur",
        color_discrete_map={"Ubisoft": "#e53935", "Autres": "#6e6e6e"},
        size=[26] * len(dff),
        size_max=28,
        labels={
            "Jeux publiÃ©s": "Nombre de jeux publiÃ©s (somme 2018â€“2024)",
            "Revenu total (milliards)": "Revenu total (en milliards d'â‚¬)"
        }
    )
    fig1.update_layout(
        showlegend=False,
        plot_bgcolor="white",
        paper_bgcolor="white",
        font=dict(color="black", size=14),
        title=dict(
            text="Relation entre le nombre de jeux publiÃ©s et le revenu total",
            font=dict(size=18, color="black"),
            x=0.5, xanchor="center"
        ),
        margin=dict(l=100, r=60, t=60, b=70),
    )
    fig1.update_xaxes(showgrid=True, gridcolor="#CCCCCC", zeroline=False,
                      automargin=True, title_font=dict(size=16, color="black"),
                      tickfont=dict(size=14, color="black"))
    fig1.update_yaxes(showgrid=True, gridcolor="#CCCCCC", zeroline=False,
                      automargin=True, title_standoff=22,
                      title_font=dict(size=16, color="black"),
                      tickfont=dict(size=14, color="black"))

    # Padding dynamique
    x_min, x_max = dff["Jeux publiÃ©s"].min(), dff["Jeux publiÃ©s"].max()
    y_min, y_max = dff["Revenu total (milliards)"].min(), dff["Revenu total (milliards)"].max()
    dx = max(6, (x_max - x_min) * 0.08)
    dy = max(0.4, (y_max - y_min) * 0.10)
    fig1.update_xaxes(range=[x_min - dx, x_max + dx])
    fig1.update_yaxes(range=[max(0, y_min - dy), y_max + dy])
    fig1.update_traces(textposition="top center", cliponaxis=False)

    st.plotly_chart(fig1, use_container_width=True)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 2.2 â€” Relation volume de jeux / revenu moyen par jeu
    # + Titre demandÃ© "DÃ©pendance aux Blogs Busters" (sans crÃ©er de section)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    

    st.markdown("""
    Cependant, cette approche atteint ses **limites**. En effet, le **revenu moyen gÃ©nÃ©rÃ© par jeu** reste infÃ©rieur Ã  celui de concurrents
    comme **Electronic Arts** ou **Take-Two**, qui publient moins de titres mais maximisent la **rentabilitÃ©** de chacun.
    """)

    if "Revenu moyen par jeu (Mâ‚¬)" not in dff.columns:
        dff["Revenu moyen par jeu (Mâ‚¬)"] = (dff["Revenu total (milliards)"] * 1000.0) / dff["Jeux publiÃ©s"]

    fig2 = px.scatter(
        dff,
        x="Jeux publiÃ©s",
        y="Revenu moyen par jeu (Mâ‚¬)",
        text="Editeur",
        color="Couleur",
        color_discrete_map={"Ubisoft": "#e53935", "Autres": "#6e6e6e"},
        size=[26] * len(dff),
        size_max=28,
        labels={"Jeux publiÃ©s": "Jeux publiÃ©s", "Revenu moyen par jeu (Mâ‚¬)": "Revenu moyen par jeu (Mâ‚¬)"}
    )
    fig2.update_layout(
        showlegend=False,
        plot_bgcolor="white",
        paper_bgcolor="white",
        font=dict(color="black", size=14),
        title=dict(
            text="Relation volume de jeux / Revenu moyen par jeu (Ubisoft vs concurrents)",
            font=dict(size=18, color="black"),
            x=0.5, xanchor="center"
        ),
        margin=dict(l=100, r=60, t=70, b=70),
    )
    fig2.update_xaxes(showgrid=True, gridcolor="#CCCCCC", zeroline=False,
                      automargin=True, title_font=dict(size=16, color="black"),
                      tickfont=dict(size=14, color="black"))
    fig2.update_yaxes(showgrid=True, gridcolor="#CCCCCC", zeroline=False,
                      automargin=True, title_standoff=22,
                      title_font=dict(size=16, color="black"),
                      tickfont=dict(size=14, color="black"))

    # Padding dynamique
    x2_min, x2_max = dff["Jeux publiÃ©s"].min(), dff["Jeux publiÃ©s"].max()
    y2_min, y2_max = dff["Revenu moyen par jeu (Mâ‚¬)"].min(), dff["Revenu moyen par jeu (Mâ‚¬)"].max()
    dx2 = max(8, (x2_max - x2_min) * 0.10)
    dy2 = max(10, (y2_max - y2_min) * 0.12)
    fig2.update_xaxes(range=[x2_min - dx2, x2_max + dx2])
    fig2.update_yaxes(range=[max(0, y2_min - dy2), y2_max + dy2])
    fig2.update_traces(textposition="top center", cliponaxis=False)

    st.plotly_chart(fig2, use_container_width=True)

    st.markdown("""
    Le **choix de miser sur la quantitÃ©** plutÃ´t que sur la **rentabilitÃ© par titre** semble diluer l'impact de chaque sortie,
    et affaiblit la capacitÃ© de l'Ã©diteur Ã  transformer ses lancements en **succÃ¨s retentissants**.
    """)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # SÃ©ries annuelles : Revenus & UnitÃ©s vendues â€” textes AVANT/APRÃˆS identiques au doc
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Chargement donnÃ©es jeux dÃ©taillÃ©es
    @st.cache_data
    def _load_jeux_csv():
        fname = "Jeux_final.csv"
        tries = [
            dict(sep=",", encoding="utf-8"),
            dict(sep=";", encoding="utf-8"),
            dict(sep=",", encoding="utf-8-sig"),
            dict(sep=";", encoding="utf-8-sig"),
            dict(sep="\t", encoding="utf-8"),
            dict(sep=",", encoding="cp1252"),
            dict(sep=";", encoding="cp1252"),
        ]
        last = None
        for opt in tries:
            try:
                df = pd.read_csv(fname, engine="python", **opt)
                if df.shape[1] >= 2:
                    return df
            except Exception as e:
                last = e
        raise RuntimeError(f"Impossible de lire {fname} : {last}")

    try:
        dfj_raw = _load_jeux_csv()
    except Exception as e:
        st.error(f"âš ï¸ Chargement de `Jeux_final.csv` impossible : {e}")
        st.stop()

    dfj = dfj_raw.copy()
    dfj.columns = [_norm(c) for c in dfj.columns]

    col_date   = _find_col(dfj.columns, ["premiere publication", "publication", "release", "date"])
    col_rev    = _find_col(dfj.columns, ["revenus", "sales", "chiffre d", "ca"])
    col_units  = _find_col(dfj.columns, ["unites", "unitÃ©s", "units", "copies", "ventes"])
    col_medhrs = _find_col(dfj.columns, ["temps median", "temps mÃ©dian", "median playtime", "temps de jeu"])

    if not (col_date and col_rev and col_units):
        st.warning("Colonnes non reconnues automatiquement. SÃ©lectionne-les ci-dessous.")
        with st.expander("Diagnostic colonnes CSV"):
            st.write(list(dfj_raw.columns))
        cols = list(dfj.columns)
        col_date  = st.selectbox("Colonne date de premiÃ¨re publication", cols, index=cols.index(col_date) if col_date else 0)
        col_rev   = st.selectbox("Colonne revenus (millions)", cols, index=cols.index(col_rev) if col_rev else 0)
        col_units = st.selectbox("Colonne unitÃ©s vendues (millions)", cols, index=cols.index(col_units) if col_units else 0)

    work = dfj[[col_date, col_rev, col_units]].rename(columns={
        col_date:  "date_pub",
        col_rev:   "revenus_m",
        col_units: "unites_m"
    }).copy()

    work["AnnÃ©e"] = pd.to_datetime(work["date_pub"], errors="coerce").dt.year
    mask_na = work["AnnÃ©e"].isna()
    if mask_na.any():
        work.loc[mask_na, "AnnÃ©e"] = work.loc[mask_na, "date_pub"].astype(str).str.extract(r"(20\d{2})", expand=False)
    work["AnnÃ©e"] = pd.to_numeric(work["AnnÃ©e"], errors="coerce").astype("Int64")

    work["Revenus (millions)"] = work["revenus_m"].apply(_to_float)
    work["UnitÃ©s vendues (millions)"] = work["unites_m"].apply(_to_float)

    annual = (work.dropna(subset=["AnnÃ©e"])
                   .groupby("AnnÃ©e", as_index=False)
                   .agg({"Revenus (millions)": "sum", "UnitÃ©s vendues (millions)": "sum"}))

    if annual.empty:
        st.error("Aucune donnÃ©e exploitable aprÃ¨s agrÃ©gation. VÃ©rifie le mapping des colonnes.")
        st.stop()

    # Texte AVANT (identique au doc)
    st.markdown("""
    Dans un marchÃ© de plus en plus **concurrentiel** oÃ¹ **lâ€™attention des joueurs est limitÃ©e**, ce positionnement nuit Ã  la 
    **visibilitÃ©** des titres dâ€™Ubisoft et limite leur capacitÃ© Ã  sâ€™imposer comme des **rÃ©fÃ©rences durables**.
    """)
    st.divider()

    # â€”â€”â€” Titre de section (mÃªme niveau que 2.1) â€”â€”â€”
    st.subheader("2.2. Une dÃ©pendance Ã  quelques blockbusters")



    # Graphique sÃ©ries annuelles
    fig3 = go.Figure()
    fig3.add_trace(go.Scatter(x=annual["AnnÃ©e"], y=annual["Revenus (millions)"],
                              mode="lines+markers", name="Revenus (millions)", line=dict(width=3)))
    fig3.add_trace(go.Scatter(x=annual["AnnÃ©e"], y=annual["UnitÃ©s vendues (millions)"],
                              mode="lines+markers", name="UnitÃ©s vendues (millions)", yaxis="y2", line=dict(width=3)))
    apply_light_theme(fig3, title_text="Ã‰volution des revenus et unitÃ©s vendues par annÃ©e",
                      x_title="AnnÃ©e", y1_title="Revenus (millions)", y2_title="UnitÃ©s vendues (millions)")
    st.plotly_chart(fig3, use_container_width=True)

    # Texte APRÃˆS (identique au doc)
    st.markdown("""
    Les donnÃ©es rÃ©vÃ¨lent une **forte concentration des revenus** sur quelques titres phares, notamment entre **2014** et **2015**, 
    pÃ©riode marquÃ©e par le lancement dâ€™Ã©pisodes majeurs dâ€™*Assassinâ€™s Creed* et de *Far Cry*.  
    Cette dynamique sâ€™est progressivement **estompÃ©e**.

    On voit que **chaque jeu contribue fortement** Ã  la volatilitÃ© des revenus, confirmant que le **succÃ¨s dâ€™Ubisoft repose davantage 
    sur quelques blockbusters** que sur lâ€™ensemble de son catalogue.

    Depuis **2019**, Ubisoft peine Ã  reproduire de tels succÃ¨s, probablement impactÃ©e par la **crise Covid-19**.  
    Le recul de ses revenus annuels sâ€™explique en partie par lâ€™absence de **nouveaux hits dâ€™ampleur**, capables de porter Ã  eux seuls 
    lâ€™exercice financier. Ce phÃ©nomÃ¨ne met en lumiÃ¨re une **dÃ©pendance excessive** Ã  des **franchises anciennes**, sans rÃ©elle relÃ¨ve.

    Ainsi, malgrÃ© un **catalogue Ã©tendu**, la **majoritÃ© des titres publiÃ©s** gÃ©nÃ¨rent **peu de valeur individuellement**.  
    Ce **dÃ©sÃ©quilibre fragilise la rÃ©silience** du modÃ¨le Ã©conomique, qui repose de fait sur une **minoritÃ© de succÃ¨s critiques et commerciaux**.

    Cette observation se **confirme aprÃ¨s analyse croisÃ©e** du **temps de jeu mÃ©dian** et des **revenus gÃ©nÃ©rÃ©s par annÃ©e**, 
    qui rÃ©vÃ¨le la mÃªme dÃ©pendance aux quelques titres Ã  fort impact.
    """)

    # ---------- Temps mÃ©dian vs revenus (si dispo) ----------
    if not col_medhrs:
        col_medhrs = _find_col(dfj.columns, ["temps median", "temps mÃ©dian", "median playtime", "temps de jeu"])
    if col_medhrs:
        df_tm = dfj_raw.copy()
        rename_map = {}
        for c in df_tm.columns:
            nc = _norm(c)
            if nc == _norm(col_date):   rename_map[c] = "PremiÃ¨re publication"
            if nc == _norm(col_rev):    rename_map[c] = "Revenus (millions)"
            if nc == _norm(col_medhrs): rename_map[c] = "Temps mÃ©dian de jeu (heures)"
        df_tm.rename(columns=rename_map, inplace=True)

        needed = {"PremiÃ¨re publication","Revenus (millions)","Temps mÃ©dian de jeu (heures)"}
        if needed.issubset(df_tm.columns):
            df_tm["PremiÃ¨re publication"] = pd.to_datetime(df_tm["PremiÃ¨re publication"], errors="coerce")
            df_tm["AnnÃ©e"] = df_tm["PremiÃ¨re publication"].dt.year
            df_tm["Revenus (millions)"] = df_tm["Revenus (millions)"].apply(_to_float)
            df_tm["Temps mÃ©dian de jeu (heures)"] = df_tm["Temps mÃ©dian de jeu (heures)"].apply(_to_float)

            df_year = (df_tm.dropna(subset=["AnnÃ©e"])
                            .groupby("AnnÃ©e", as_index=False)
                            .agg({"Revenus (millions)": "sum",
                                  "Temps mÃ©dian de jeu (heures)": "median"}))

            if not df_year.empty:
                fig4 = go.Figure()
                fig4.add_trace(go.Scatter(x=df_year["AnnÃ©e"], y=df_year["Temps mÃ©dian de jeu (heures)"],
                                          mode="lines+markers", name="Temps mÃ©dian de jeu (h)", line=dict(width=3)))
                fig4.add_trace(go.Scatter(x=df_year["AnnÃ©e"], y=df_year["Revenus (millions)"],
                                          mode="lines+markers", name="Revenus (millions)", yaxis="y2", line=dict(width=3)))
                apply_light_theme(fig4, title_text="Temps mÃ©dian de jeu vs Revenus (annuel)",
                                  x_title="AnnÃ©e", y1_title="Temps mÃ©dian de jeu (h)", y2_title="Revenus (millions)")
                st.plotly_chart(fig4, use_container_width=True)
            # ---------- Bloc texte Ã  insÃ©rer entre les deux graphiques ----------
    st.markdown("""
En effet, **entre 2005 et 2014**, Ubisoft enregistre une **croissance continue** de ces deux indicateurs,
avec un **pic autour de 2014â€“2015**. Comme expliquÃ© prÃ©cÃ©demment, cette pÃ©riode correspond Ã  la sortie de
**titres majeurs**, souvent bien accueillis par la **critique** comme par les **joueurs**, et jouant un
**rÃ´le structurant** dans les revenus de lâ€™entreprise.

**Cependant, aprÃ¨s 2018**, les **revenus chutent significativement**, tandis que le **temps de jeu mÃ©dian
reste Ã©levÃ©**. Ce dÃ©calage indique que, malgrÃ© une baisse de performance Ã©conomique, Ubisoft **conserve une
base de joueurs fidÃ¨les**, probablement attachÃ©s Ã  ses **licences historiques**.

Ce phÃ©nomÃ¨ne illustre un **problÃ¨me de renouvellement dâ€™offre** : Ubisoft **capitalise sur ses anciens succÃ¨s**,
mais **ne parvient plus Ã  recrÃ©er lâ€™Ã©lan** des prÃ©cÃ©dentes gÃ©nÃ©rations de **blockbusters**.
""")
    st.divider()
    st.subheader("2.3. Des modÃ¨les Ã©conomiques mal exploitÃ©s")
    st.markdown(
    "Entre 2013 et 2015, Ubisoft parvient Ã  capter lâ€™attention du marchÃ© avec plusieurs initiatives Free-to-Play "
    "et des titres Ã  fort potentiel multijoueur (*The Mighty Quest for Epic Loot, Trackmania, Brawlhalla*, etc.)."
)

    # ---------- ModÃ¨les Ã©conomiques (gratuits vs payants) ----------
    col_model = _find_col(dfj.columns, ["modele", "modÃ¨le", "business", "monet", "model", "pricing", "f2p", "free", "gratuit"])
    col_price = _find_col(dfj.columns, ["prix", "price"])

    work2 = dfj[[col_date, col_units] + ([col_model] if col_model else []) + ([col_price] if col_price else [])].copy()
    work2.rename(columns={col_date:"date_pub", col_units:"unites"}, inplace=True)
    work2["AnnÃ©e"] = pd.to_datetime(work2["date_pub"], errors="coerce").dt.year
    work2["UnitÃ©s vendues (millions)"] = work2["unites"].apply(_to_float)

    def _is_free(row) -> bool:
        if col_model:
            s = str(row[col_model]).lower()
            if any(k in s for k in ["free", "gratuit", "f2p", "free-to-play", "free to play"]):
                return True
        if col_price:
            try:
                p = _to_float(row[col_price])
                if p == 0:
                    return True
            except:
                pass
        return False

    work2["Type"] = work2.apply(lambda r: "Jeux gratuits" if _is_free(r) else "Jeux payants", axis=1)

    g = (work2.dropna(subset=["AnnÃ©e"])
              .groupby(["AnnÃ©e","Type"], as_index=False)
              .agg({"UnitÃ©s vendues (millions)":"sum"}))

    if not g.empty:
        import plotly.graph_objects as go
        wide = g.pivot(index="AnnÃ©e", columns="Type", values="UnitÃ©s vendues (millions)").fillna(0.0).sort_index()
        fig5 = go.Figure()
        if "Jeux payants" in wide.columns:
            fig5.add_trace(go.Scatter(x=wide.index, y=wide["Jeux payants"],
                                      mode="lines+markers", name="Jeux payants", line=dict(width=3)))
        if "Jeux gratuits" in wide.columns:
            fig5.add_trace(go.Scatter(x=wide.index, y=wide["Jeux gratuits"],
                                      mode="lines+markers", name="Jeux gratuits", line=dict(width=3, dash="dash")))
        apply_light_theme(fig5, title_text="Ã‰volution des unitÃ©s vendues : Jeux gratuits vs payants",
                          x_title="AnnÃ©e", y1_title="UnitÃ©s vendues (millions)")
        st.plotly_chart(fig5, use_container_width=True)

        # ---------- Bloc de conclusion (Ã  insÃ©rer Ã  la fin du chapitre) ----------
    
    st.markdown("""
    Pourtant, cette **dynamique prometteuse** nâ€™a pas Ã©tÃ© pÃ©rennisÃ©e. Le **modÃ¨le freemium**, pourtant porteur sur le long terme
    pour dâ€™autres Ã©diteurs (comme *Epic Games* avec *Fortnite*), nâ€™a **jamais Ã©tÃ© solidement ancrÃ©** dans la stratÃ©gie
    produit dâ€™Ubisoft.

    Cette **incapacitÃ© Ã  renouveler les formats**, Ã  proposer des **expÃ©riences Ã©conomiques innovantes** ou Ã  **sâ€™adapter aux tendances**
    (*abonnement*, *cross-platform*, *multijoueur compÃ©titif*, etc.) **risque dâ€™isoler progressivement Ubisoft** dâ€™une partie de la communautÃ©,
    notamment les **joueurs plus jeunes** ou **plus actifs sur mobile et PC**.
    """)
    st.divider()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PAGE 4 : PERCEPTION ET CRITIQUE â€” RUPTURE AVEC LES JOUEURS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
elif page == "Perception et critique : la rupture avec les joueurs":
    import pandas as pd
    import numpy as np
    import re
    import matplotlib.pyplot as plt
    import seaborn as sns

    st.title("ğŸ§© Perception et critique : la rupture avec les joueurs")
    st.markdown("""
    Au-delÃ  des performances financiÃ¨res et des stratÃ©gies de dÃ©veloppement,  
    lâ€™analyse de la **rÃ©ception critique** des jeux Ubisoft apporte un Ã©clairage essentiel.  

    En observant les notes attribuÃ©es par la **presse spÃ©cialisÃ©e** et les **joueurs** sur des plateformes comme **Metacritic**,  
    on met en Ã©vidence une **communautÃ© de joueurs** qui semble **lÃ©gÃ¨rement plus polarisÃ©e**  
    et parfois **prÃªte Ã  noter des jeux Ã  0**.
    """)


    # â”€â”€â”€â”€â”€â”€â”€â”€â”€ Lecture directe du CSV local
    @st.cache_data
    def load_scores():
        tries = [
            dict(sep=",", encoding="utf-8"),
            dict(sep=";", encoding="utf-8"),
            dict(sep=",", encoding="utf-8-sig"),
            dict(sep=";", encoding="utf-8-sig"),
            dict(sep=",", encoding="cp1252"),
            dict(sep=";", encoding="cp1252"),
        ]
        last_err = None
        for opt in tries:
            try:
                return pd.read_csv("ubisoft_scores.csv", engine="python", **opt)
            except Exception as e:
                last_err = e
        st.error(f"âš ï¸ Impossible de lire `ubisoft_scores.csv`. VÃ©rifie qu'il est bien placÃ© Ã  cÃ´tÃ© de `app.py`. DÃ©tails : {last_err}")
        st.stop()

    raw = load_scores()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€ VÃ©rification des colonnes attendues
    expected_cols = {"Press_Score", "Users_Score"}
    if not expected_cols.issubset(raw.columns):
        st.error("âš ï¸ Le fichier CSV doit contenir les colonnes **Press_Score** et **Users_Score**.")
        st.stop()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€ Nettoyage des donnÃ©es
    def _to_num(x):
        if pd.isna(x): return np.nan
        s = str(x).strip().lower()
        if s in {"tbd", "na", "n/a", "none", "null", "-", ""}:
            return np.nan
        s = s.replace("\u202f", "").replace("\xa0", "").replace(",", ".")
        s = re.sub(r"[^0-9\.\-]", "", s)
        try:
            return float(s)
        except:
            return np.nan

    df_notes = pd.DataFrame({
        "Press_Score": raw["Press_Score"].apply(_to_num),
        "Users_Score": raw["Users_Score"].apply(_to_num),
    }).dropna()

    # Conversion auto 0â€“100 â†’ 0â€“10
    if df_notes["Press_Score"].max() > 10:
        df_notes["Press_Score"] /= 10.0
    if df_notes["Users_Score"].max() > 10:
        df_notes["Users_Score"] /= 10.0

    # Filtre borne [0,10]
    df_notes = df_notes[
        (df_notes["Press_Score"].between(0, 10)) &
        (df_notes["Users_Score"].between(0, 10))
    ]

    if df_notes.empty:
        st.error("âš ï¸ Aucune donnÃ©e exploitable aprÃ¨s nettoyage (scores attendus entre 0 et 10).")
        st.stop()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€ Stats descriptives (COUNT + MEAN uniquement)
    st.subheader(" Statistiques descriptives")
    stats = df_notes.describe().loc[["count", "mean"]].round(3)
    st.dataframe(stats, use_container_width=True)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€ Graphiques : Presse vs Joueurs
    st.subheader(" Comparaison des distributions")
    x_min, x_max = 0, 10
    sns.set_style("whitegrid")

    fig, axs = plt.subplots(2, 1, figsize=(10, 8), sharex=True)

    # Presse
    sns.histplot(df_notes["Press_Score"], bins=20, kde=True, color="#4CAF50", ax=axs[0])
    axs[0].set_title("Distribution des notes de la Presse (sur 10)", fontsize=12)
    axs[0].set_ylabel("Nombre de jeux")
    axs[0].set_xlim(x_min, x_max)

    # Joueurs
    sns.histplot(df_notes["Users_Score"], bins=20, kde=True, color="#87CEEB", ax=axs[1])
    axs[1].set_title("Distribution des notes utilisateurs (sur 10)", fontsize=12)
    axs[1].set_xlabel("Notes")
    axs[1].set_ylabel("Nombre de jeux")
    axs[1].set_xlim(x_min, x_max)

    plt.tight_layout()
    st.pyplot(fig)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€ Analyse rapide
    st.subheader(" Analyse")
    st.markdown("""
    - **Presse** : notes majoritairement concentrÃ©es entre **6 et 8**, reflÃ©tant une Ã©valuation globalement positive.
    - **Joueurs** : distribution plus **Ã©talÃ©e**, avec davantage de notes trÃ¨s basses â†’ signe d'une **polarisation**.
    - Cet Ã©cart rÃ©vÃ¨le une diffÃ©rence de perception : Ubisoft convainc la presse mais divise parfois sa communautÃ©.
    """)
    # â€”â€”â€” DÃ©tection Year + agrÃ©gations annuelles
    import unicodedata, re
    def _norm(s: str) -> str:
        s = unicodedata.normalize("NFKD", str(s))
        s = "".join(c for c in s if not unicodedata.combining(c))
        return re.sub(r"[\s\-_\/]+", " ", s).strip().lower()

    def _extract_year_column(df: pd.DataFrame) -> pd.Series | None:
        # 1) colonnes de date
        for c in df.columns:
            n = _norm(c)
            if any(k in n for k in ["release", "premiere", "publication", "date", "year", "annee", "annÃ©e"]):
                y = pd.to_datetime(df[c], errors="coerce").dt.year
                if y.notna().sum() > 0:
                    return y
        # 2) colonnes numÃ©riques dÃ©jÃ  en annÃ©es
        for c in df.columns:
            if pd.api.types.is_numeric_dtype(df[c]):
                y = pd.to_numeric(df[c], errors="coerce")
                if ((y >= 1990) & (y <= 2035)).sum() > 0:
                    return y
        return None

    year_series = _extract_year_column(raw)
    if year_series is None:
        st.warning("Aucune colonne de date/annÃ©e reconnue : les graphiques temporels ne peuvent pas Ãªtre tracÃ©s.")
    else:
        work = pd.DataFrame({
            "Year": year_series,
            "Press_Score": df_notes["Press_Score"].values,  # scores dÃ©jÃ  nettoyÃ©s/ramenÃ©s sur 10
            "Users_Score": df_notes["Users_Score"].values,
        }).dropna()
        work = work[(work["Year"] >= 1995) & (work["Year"] <= 2035)]

        yearly = (work.groupby("Year", as_index=False)
                        .agg(Press=("Press_Score","mean"),
                             Users=("Users_Score","mean"))
                        .sort_values("Year"))

        # â€”â€”â€” Graphique 1 : courbes annuelles
        st.subheader(" Notes moyennes par annÃ©e â€” Presse vs Joueurs")
        fig_line, axl = plt.subplots(figsize=(10, 5))
        axl.plot(yearly["Year"], yearly["Press"], marker="o", linewidth=2.2, label="Presse", color="#2E7D32")
        axl.plot(yearly["Year"], yearly["Users"], marker="o", linewidth=2.2, label="Joueurs", color="#FB8C00")
        axl.set_xlabel("AnnÃ©e de sortie"); axl.set_ylabel("Note moyenne (sur 10)")
        axl.grid(True, linestyle="--", alpha=0.35)
        axl.legend(title="Source", frameon=True)

        # repÃ¨re Â« dÃ©crochage Â» (si l'annÃ©e est dans la sÃ©rie)
        if (yearly["Year"] >= 2014).any() and (yearly["Year"] <= 2014).any():
            axl.axvline(2014, color="#757575", linestyle="--", alpha=0.6)
            ymin, ymax = axl.get_ylim()
            axl.text(2014 + 0.2, ymin + 0.05*(ymax-ymin),
                     "DÃ©crochage des notes des joueurs", fontsize=9, color="#616161")

        st.pyplot(fig_line)
        # â€”â€”â€” Graphique 2 : Ã©cart moyen annuel (Users âˆ’ Press)
        st.subheader(" Ã‰cart moyen entre notes utilisateurs et presse ")
        delta = yearly.copy()
        delta["Diff"] = delta["Users"] - delta["Press"]

        # couleurs: bleu si positif, dÃ©gradÃ© de rouge si nÃ©gatif
        import matplotlib as mpl
        reds = mpl.cm.get_cmap("Reds")
        neg_vals = delta["Diff"].clip(upper=0).abs()
        if neg_vals.max() == 0:
            neg_norm = np.zeros_like(neg_vals)
        else:
            neg_norm = neg_vals / neg_vals.max()

        colors = []
        for d, nn in zip(delta["Diff"], neg_norm):
            if d >= 0:
                colors.append("#1f77b4")          # bleu (joueurs plus gÃ©nÃ©reux)
            else:
                colors.append(reds(0.35 + 0.55*nn))  # rouge plus sombre si lâ€™Ã©cart est grand

        fig_bar, axb = plt.subplots(figsize=(10, 5))
        axb.bar(delta["Year"], delta["Diff"], color=colors, width=0.8, edgecolor="none")
        axb.axhline(0, color="black", linewidth=1)
        axb.set_xlabel("AnnÃ©e de sortie"); axb.set_ylabel("Score delta (Users âˆ’ Press)")
        axb.grid(axis="y", linestyle="--", alpha=0.35)

        # petite lÃ©gende manuelle
        from matplotlib.patches import Patch
        legend_elems = [
            Patch(facecolor="#1f77b4", label="Joueurs plus gÃ©nÃ©reux que la presse"),
            Patch(facecolor=reds(0.8), label="Joueurs plus critiques que la presse"),
        ]
        axb.legend(handles=legend_elems, title="InterprÃ©tation des couleurs", frameon=True)

        st.pyplot(fig_bar)
    st.markdown("""


Historiquement, les jeux Ubisoft ont reÃ§u des Ã©valuations relativement proches entre la **presse** et les **joueurs**. 
Jusquâ€™en **2014**, la moyenne des notes utilisateurs est stable autour de **7/10**, tandis que la presse affiche 
gÃ©nÃ©ralement des scores entre **7 et 8/10**. Les Ã©carts sont modÃ©rÃ©s, et les critiques convergent globalement.

Ã€ partir de **2015**, une **fracture de perception** commence Ã  se dessiner : les joueurs deviennent plus critiques, 
attribuant des notes **significativement infÃ©rieures** Ã  celles de la presse. Cette tendance sâ€™accentue au fil des annÃ©es, 
jusquâ€™Ã  atteindre un **Ã©cart moyen de â€“2,3 points** entre les deux types dâ€™Ã©valuateurs en **2022**. Dans certains cas, 
les utilisateurs attribuent des notes **trÃ¨s basses (0 Ã  4/10)**, souvent motivÃ©es par une frustration liÃ©e Ã  la 
**qualitÃ© technique** ou Ã  la **dÃ©ception** vis-Ã -vis des promesses initiales.

La presse, quant Ã  elle, reste globalement **modÃ©rÃ©e** dans ses notations, avec peu dâ€™Ã©volutions Ã  la baisse. 
Ce dÃ©calage persistant entre **qualitÃ© perÃ§ue par les joueurs** et **reconnaissance critique** devient un marqueur 
structurel de la **crise** que traverse Ubisoft. Il tÃ©moigne dâ€™un **dÃ©salignement** entre lâ€™expÃ©rience rÃ©elle des 
utilisateurs et le produit livrÃ©, alimentÃ© par des Ã©lÃ©ments rÃ©currents dans les critiques : **manque dâ€™innovation**, 
**gameplay rÃ©pÃ©titif**, **bugs techniques**, ou encore **promesses non tenues**.
""")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 3) Top & Flop Ubisoft â€“ Score moyen global (presse + utilisateurs)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    import re, unicodedata
    import matplotlib.pyplot as plt
    import seaborn as sns

    st.subheader(" Top & Flop Ubisoft â€“ Score moyen global (presse + utilisateurs)")

    # --- Helpers pour retrouver les colonnes "Name", "Platform" et "Year" si elles ne sont pas dÃ©jÃ  dans df_notes
    def _norm(s: str) -> str:
        s = unicodedata.normalize("NFKD", str(s))
        s = "".join(c for c in s if not unicodedata.combining(c))
        return re.sub(r"[\s\-_\/]+", " ", s).strip().lower()

    def _extract_year_column(df: pd.DataFrame) -> pd.Series | None:
        # 1) colonnes de date
        for c in df.columns:
            n = _norm(c)
            if any(k in n for k in ["release", "premiere", "publication", "date", "year", "annee", "annÃ©e"]):
                y = pd.to_datetime(df[c], errors="coerce").dt.year
                if y.notna().sum() > 0:
                    return y
        # 2) colonnes numÃ©riques dÃ©jÃ  en annÃ©es
        for c in df.columns:
            if pd.api.types.is_numeric_dtype(df[c]):
                y = pd.to_numeric(df[c], errors="coerce")
                if ((y >= 1990) & (y <= 2035)).sum() > 0:
                    return y
        return None

    # On part de df_notes (dÃ©jÃ  nettoyÃ© + ramenÃ© sur 10) et du DataFrame brut 'raw' lu en dÃ©but de page 4
    df_plot = df_notes.copy()

    # Ajoute Year si manquant
    if "Year" not in df_plot.columns:
        y = _extract_year_column(raw)
        if y is not None:
            df_plot["Year"] = y
        else:
            st.error("Impossible dâ€™identifier la colonne AnnÃ©e. Ajoute une colonne 'Year' ou une date de sortie dans le CSV.")
            st.stop()

    # Ajoute Name si manquant
    if "Name" not in df_plot.columns:
        name_col = next((c for c in raw.columns if _norm(c) in {"name","titre","title","game","jeu"} 
                         or any(k in _norm(c) for k in ["name","title","game","jeu","titre"])), None)
        if name_col:
            df_plot["Name"] = raw[name_col]
        else:
            df_plot["Name"] = [f"Jeu {i}" for i in range(len(df_plot))]

    # Ajoute Platform si manquant
    if "Platform" not in df_plot.columns:
        plat_col = next((c for c in raw.columns if any(k in _norm(c) for k in ["platform","console","system"])), None)
        df_plot["Platform"] = raw[plat_col] if plat_col else "N/A"

    # Ajoute Score_Avg si manquant
    if "Score_Avg" not in df_plot.columns:
        df_plot["Score_Avg"] = df_plot[["Press_Score","Users_Score"]].mean(axis=1)

    # --- Ton code adaptÃ© Ã  Streamlit ---
    # Filtrer les jeux sortis depuis 2015
    df_notes_recent = df_plot[df_plot["Year"] >= 2015].copy()

    # Top 10 des jeux Ubisoft selon score_avg
    top_avg = (df_notes_recent.sort_values(by="Score_Avg", ascending=False)
               .drop_duplicates(subset=["Name","Platform"])
               .head(10))

    # Flop 10 des jeux Ubisoft selon score_avg
    flop_avg = (df_notes_recent.sort_values(by="Score_Avg", ascending=True)
                .drop_duplicates(subset=["Name","Platform"])
                .head(10))

    # Fusion pour plot
    topflop_avg = pd.concat([top_avg.assign(cat="Top"), flop_avg.assign(cat="Flop")], ignore_index=True)

    if topflop_avg.empty:
        st.warning("Aucune donnÃ©e aprÃ¨s filtrage (Year â‰¥ 2015). VÃ©rifie les colonnes Year/Name/Platform.")
    else:
        # Tri de lâ€™affichage (du plus faible au plus fort, puis inversion de lâ€™axe Y pour avoir les meilleurs en haut)
        order_names = topflop_avg.sort_values("Score_Avg", ascending=True)["Name"]

        fig, ax = plt.subplots(figsize=(12, 8))
        sns.barplot(
            data=topflop_avg,
            y="Name",
            x="Score_Avg",
            hue="cat",
            dodge=False,
            order=order_names,
            palette={"Top": "green", "Flop": "red"},
            ax=ax
        )
        ax.set_title("Top & Flop Ubisoft â€“ Score moyen global (presse + utilisateurs)", fontsize=13)
        ax.set_xlabel("Score moyen (/10)")
        ax.set_ylabel("Jeu")
        ax.grid(axis="x", linestyle="--", alpha=0.35)
        ax.legend(title="CatÃ©gorie", frameon=True)
        ax.invert_yaxis()  # meilleurs en haut

        # Ajout des valeurs au bout des barres
        for p in ax.patches:
            width = p.get_width()
            y = p.get_y() + p.get_height() / 2
            ax.text(width + 0.05, y, f"{width:.1f}", va="center", fontsize=9)

        plt.tight_layout()
        st.pyplot(fig)
    # â€”â€”â€” Texte d'analyse : Top & Flop Ubisoft 2015â€“2025
    st.markdown("""
Sur la pÃ©riode **2015â€“2025**, lâ€™Ã©tude des **notes moyennes globales** (*presse + utilisateurs*) met en Ã©vidence une
**tendance prÃ©occupante** : les meilleurs jeux Ubisoft rÃ©cents ne sont pas ceux qui bÃ©nÃ©ficient du plus fort
**soutien marketing**, ni ceux issus des **franchises historiques**.

Parmi les titres les mieux reÃ§us, on retrouve notamment **Beyond Good & Evil 20th Anniversary Edition** ou
**Prince of Persia: The Lost Crown** â€“ des jeux moins exposÃ©s mÃ©diatiquement.  
Ã€ lâ€™inverse, plusieurs **blockbusters trÃ¨s attendus**, Ã  **gros budget**, Ã©chouent Ã  convaincre :
**Ghost Recon Breakpoint**, **The Settlers: New Allies**, ou encore **Just Dance 2024 Edition**
reÃ§oivent des notes particuliÃ¨rement basses, en dÃ©calage avec leurs ambitions.

Ce phÃ©nomÃ¨ne appuie davantage sur la **diminution de la confiance des joueurs** envers les grands lancements Ubisoft.
Lâ€™un des exemples les plus emblÃ©matiques de cette rupture est le cas de **Skull & Bones**, que nous allons analyser
dans la derniÃ¨re partie.
""")

    # â€”â€”â€” Barre de sÃ©paration avant la section 3.3
    st.markdown("---")

    # â€”â€”â€” Partie 3.3 : Le cas Skull & Bones
    st.subheader("3.3. Le cas Skull & Bones : un Ã©chec emblÃ©matique")

    st.markdown("""
Lâ€™Ã©pisode le plus marquant de cette rupture entre Ubisoft et sa communautÃ© est incarnÃ© par **Skull & Bones**,
considÃ©rÃ© comme lâ€™un des plus gros Ã©checs rÃ©cents de lâ€™Ã©diteur.  
Ce jeu, censÃ© capitaliser sur le succÃ¨s de *Assassinâ€™s Creed IV: Black Flag* et sur lâ€™engouement pour les
**thÃ©matiques pirates**, a connu un **dÃ©veloppement chaotique** Ã©talÃ© sur prÃ¨s de **10 ans**.  
Ã€ sa sortie, il recueille une **note utilisateur catastrophique de 3/10**, tandis que la presse reste
**modÃ©rÃ©ment indulgente**.

Un **nuage de mots** gÃ©nÃ©rÃ© Ã  partir des critiques utilisateurs sur *Metacritic* permet de mettre en lumiÃ¨re
cette perception.  
Les termes les plus frÃ©quents parlent dâ€™eux-mÃªmes :  
*â€œboringâ€*, *â€œrepetitiveâ€*, *â€œmoneyâ€*, *â€œcombatâ€*, *â€œwasteâ€*, *â€œgameplayâ€*, *â€œdisappointingâ€*, *â€œBlack Flagâ€*, etc.

Ils illustrent une combinaison de **dÃ©ception**, **dâ€™ennui** et de **frustration Ã©conomique**.  
Beaucoup de joueurs font explicitement rÃ©fÃ©rence Ã  *Black Flag*, renforÃ§ant la comparaison avec un jeu sur une
**thÃ©matique proche**, perÃ§u comme **bien mieux rÃ©ussi**, pourtant sorti **dix ans plus tÃ´t**.
""")
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Nuage de mots nÃ©gatifs â€” Skull & Bones (stopwords fournis + suppression "skull" et "bones")
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    import sys
    import subprocess
    import string
    import unicodedata
    import re
    import pandas as pd
    import matplotlib.pyplot as plt
    from wordcloud import WordCloud, STOPWORDS
    from textblob import TextBlob

    st.subheader(" Nuage de mots des critiques nÃ©gatives â€” Skull & Bones")

    # --- Installer automatiquement wordcloud & textblob si manquants
    def _ensure_package(mod_name, pip_name=None):
        try:
            __import__(mod_name)
        except ModuleNotFoundError:
            with st.spinner(f"Installation de `{pip_name or mod_name}`â€¦"):
                subprocess.check_call([sys.executable, "-m", "pip", "install", pip_name or mod_name])
            __import__(mod_name)

    _ensure_package("wordcloud")
    _ensure_package("textblob")

    # --- Lecture CSV critiques
    @st.cache_data
    def _read_critiques():
        tries = [
            dict(sep=",", encoding="utf-8"),
            dict(sep=";", encoding="utf-8"),
            dict(sep=",", encoding="utf-8-sig"),
            dict(sep=";", encoding="utf-8-sig"),
            dict(sep=",", encoding="cp1252"),
            dict(sep=";", encoding="cp1252"),
            dict(sep="\t", encoding="utf-8"),
        ]
        for path in ["ubisoft_critiques.csv", "data/ubisoft_critiques.csv"]:
            for opt in tries:
                try:
                    return pd.read_csv(path, engine="python", **opt)
                except Exception:
                    continue
        raise RuntimeError("âš ï¸ Fichier `ubisoft_critiques.csv` introuvable.")

    try:
        dfc_raw = _read_critiques()
    except Exception as e:
        st.error(f"âš ï¸ {e}")
        st.stop()

    # --- DÃ©tection colonnes Jeu / Critique
    def _norm(s: str) -> str:
        s = unicodedata.normalize("NFKD", str(s))
        s = "".join(c for c in s if not unicodedata.combining(c))
        return re.sub(r"[\s\-_\/]+", " ", s).strip().lower()

    cols_map = {_norm(c): c for c in dfc_raw.columns}
    col_game = next((cols_map[k] for k in ["jeu","name","title","game","nom"] if k in cols_map), None)
    col_text = next((cols_map[k] for k in ["critique","review","user review","user_review","comment","texte","text"] if k in cols_map), None)
    if not (col_game and col_text):
        st.error("âš ï¸ Le CSV des critiques doit contenir une colonne **Jeu/Name** et **Critique/Review**.")
        st.stop()

    dfc = dfc_raw[[col_game, col_text]].rename(columns={col_game:"Jeu", col_text:"Critique"}).dropna()

    # --- Filtrer uniquement Skull & Bones
    jeu_cible = "Skull and Bones"
    df_skull = dfc[dfc["Jeu"].astype(str).str.lower().str.contains("skull")]

    if df_skull.empty:
        st.warning("âš ï¸ Aucune critique trouvÃ©e pour 'Skull & Bones'. VÃ©rifie ton CSV.")
    else:
        # --- Garder uniquement les critiques NEGATIVES
        critiques_neg = df_skull["Critique"].dropna().astype(str)
        critiques_neg = critiques_neg[critiques_neg.apply(lambda x: TextBlob(x).sentiment.polarity < 0)]

        # --- Nettoyage texte
        texte = " ".join(critiques_neg.str.lower())
        texte = texte.translate(str.maketrans("", "", string.punctuation))

        # --- Stopwords EXACTS : uniquement ta liste + suppression des noms "skull" et "bones"
        custom_stopwords = set(STOPWORDS)
        custom_stopwords.update([
            'game', 'games', 'ubisoft', 'play', 'player', 'playing',
            'dlc', 'edition', 'content', 'series', 'experience',
            'version', 'new', 'like', 'one', 'ship', 'pirate','fun','combat',
            'skull', 'bones'  # â† AjoutÃ©s ici pour ne PAS les afficher
        ])

        # --- Liste des mots clÃ©s Ã  mettre en ROUGE vif
        highlight_words = {
            "boring": "#d62728",
            "repetitive": "#d62728",
            "money": "#d62728",
            "combat": "#d62728",
            "waste": "#d62728",
            "gameplay": "#d62728",
            "disappointing": "#d62728",
            "black": "#d62728",
            "flag": "#d62728"
        }

        # --- Fonction de coloration dynamique des mots
        def color_function(word, **kwargs):
            return highlight_words.get(word.lower(), "lightcoral")

        # --- GÃ©nÃ©ration du WordCloud (style projet)
        wordcloud = WordCloud(
            width=1200,
            height=700,
            background_color="white",
            stopwords=custom_stopwords,
            color_func=color_function
        ).generate(texte)

        # --- Affichage graphique
        fig, ax = plt.subplots(figsize=(12, 8))
        ax.imshow(wordcloud, interpolation="bilinear")
        ax.axis("off")
        plt.tight_layout()
        st.pyplot(fig)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ğŸ“Š Section 3.4 : Un dÃ©salignement total entre budget, durÃ©e et rÃ©sultat
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    import matplotlib.pyplot as plt
    import seaborn as sns
    import pandas as pd

    # --- Titre de la section
    st.markdown("## 3.4. Un dÃ©salignement total entre budget, durÃ©e et rÃ©sultat")

    # â€”â€”â€” Texte introductif (au-dessus du graphique budget)
    st.markdown("""
Ce qui rend **Skull & Bones** encore plus problÃ©matique, câ€™est la **disproportion**
entre les **moyens engagÃ©s** et la **qualitÃ© perÃ§ue**.  
Avec un **budget estimÃ© Ã  plus de 200 millions de dollars** *(voire **500 M$** selon certaines sources,
notamment dâ€™anciens employÃ©s dâ€™Ubisoft)*, le jeu se classe parmi les **plus ambitieux de lâ€™industrie**,  
aux cÃ´tÃ©s de productions ayant connu un **succÃ¨s Ã©norme** comme **GTA V** ou **Call of Duty: Modern Warfare**.
""")

    # --- DonnÃ©es fictives de l'Ã©tude AAA (Ã  adapter selon tes fichiers CSV si nÃ©cessaire)
    data_budget = {
        "Jeu": [
            "Assassin's Creed II", "Far Cry 3", "The Last of Us Part II",
            "FIFA 23", "Elden Ring", "The Legend of Zelda: BOTW",
            "Skull and Bones", "Call of Duty: Modern Warfare (2019)",
            "GTA V", "Red Dead Redemption 2"
        ],
        "Budget": [80, 90, 110, 120, 130, 150, 200, 220, 265, 350]
    }

    df_budget = pd.DataFrame(data_budget)

    # --- CrÃ©ation du graphique
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.barplot(
        data=df_budget,
        y="Jeu",
        x="Budget",
        palette=["#6baed6" if jeu != "Skull and Bones" else "#fdae6b" for jeu in df_budget["Jeu"]],
        ax=ax
    )

    # --- Ligne rouge verticale sur le budget de Skull & Bones
    ax.axvline(200, color="red", linestyle="--", linewidth=2, label="Budget Skull & Bones")

    # --- Personnalisation graphique
    ax.set_title("Budgets de production des jeux AAA", fontsize=14, fontweight="bold")
    ax.set_xlabel("Budget (en millions $)")
    ax.set_ylabel("Jeu")
    ax.legend()

    # --- Affichage
    st.pyplot(fig)
    # â€”â€”â€” Texte dâ€™interprÃ©tation (aprÃ¨s le graphique budget)
    st.markdown("""
En comparant la **durÃ©e de dÃ©veloppement**, le **budget** et la **note Metacritic** de ces jeux,
on observe que **Skull & Bones** se positionne Ã  lâ€™**extrÃªme** : **coÃ»teux**, **le plus long Ã  produire**,
avec **le score critique le plus bas**.
""")
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # DurÃ©e de DÃ©veloppement vs Note Metacritic (bulles = budget) â€” version Seaborn/Matplotlib pour Streamlit
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    import pandas as pd
    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    import streamlit as st

    st.subheader(" DurÃ©e de DÃ©veloppement vs Note Metacritic â€” ğŸ’° Taille des bulles = Budget de dÃ©veloppement")

    @st.cache_data
    def load_aaa():
        # Charge ton fichier tel quel (mÃªmes noms de colonnes que dans ton code)
        tries = [
            dict(sep=",", encoding="utf-8"),
            dict(sep=";", encoding="utf-8"),
            dict(sep=",", encoding="utf-8-sig"),
            dict(sep=";", encoding="utf-8-sig"),
            dict(sep=",", encoding="cp1252"),
            dict(sep=";", encoding="cp1252"),
            dict(sep="\t", encoding="utf-8"),
        ]
        last_err = None
        for path in ["jeux_AAA_metacritic_only.csv", "data/jeux_AAA_metacritic_only.csv"]:
            for opt in tries:
                try:
                    df = pd.read_csv(path, engine="python", **opt)
                    return df
                except Exception as e:
                    last_err = e
        raise RuntimeError(f"Impossible de lire le CSV : {last_err}")

    # âœ On suppose que ton CSV a bien les colonnes : title, publisher, budget_musd, development_years, metacritic_score
    df_full = load_aaa()
    required = {"title", "publisher", "budget_musd", "development_years", "metacritic_score"}
    if not required.issubset(df_full.columns):
        st.error(f"Colonnes attendues manquantes. Il faut au minimum : {sorted(required)}")
        st.stop()

    # â€” Graphique identique Ã  ton code
    plt.figure(figsize=(14, 8))
    sns.set(style="whitegrid", font_scale=1.1)

    # Palette dynamique basÃ©e sur le nombre d'Ã©diteurs
    n_publishers = df_full["publisher"].nunique()
    palette = sns.color_palette("tab10", n_colors=n_publishers)

    plot = sns.scatterplot(
        data=df_full,
        x="development_years",
        y="metacritic_score",
        hue="publisher",
        size="budget_musd",
        sizes=(200, 2000),
        alpha=0.9,
        edgecolor="black",
        linewidth=0.5,
        palette=palette,
        legend="brief"
    )

    # Titres des jeux au centre des bulles (comme ton code)
    for _, row in df_full.iterrows():
        plt.text(
            row["development_years"],
            row["metacritic_score"],
            row["title"],
            fontsize=10,
            ha="center",
            va="center",
            color="black",
            weight="bold",
        )

    # Mise en page (identique Ã  lâ€™esprit de ton snippet)
    plt.title("ğŸ® DurÃ©e de DÃ©veloppement vs Note Metacritic\nğŸ’° Taille des bulles = Budget de dÃ©veloppement",
              fontsize=16, weight="bold")
    plt.xlabel("DurÃ©e de dÃ©veloppement (annÃ©es)", fontsize=12)
    plt.ylabel("Note Metacritic", fontsize=12)
    plt.grid(True, linestyle="--", alpha=0.6)

    # LÃ©gendes sur la droite
    plt.legend(bbox_to_anchor=(1.05, 1), loc="upper left",
               title="Ã‰diteur / Budget", borderaxespad=1)

    # Petites marges pour Ã©viter de couper les bulles/labels
    plt.margins(x=0.08, y=0.06)

    # Optionnel : forcer un peu de marge en X pour que tout soit bien â€œentierâ€
    xmin, xmax = df_full["development_years"].min(), df_full["development_years"].max()
    plt.xlim(xmin - 0.5, xmax + 1.0)

    plt.tight_layout()

    # âœ Affichage Streamlit
    st.pyplot(plt.gcf(), clear_figure=True)
    st.markdown("""
Ce graphique met en lumiÃ¨re un dÃ©calage profond entre effort, coÃ»t et valeur livrÃ©e. Il constitue un cas dâ€™Ã©cole dâ€™Ã©chec produit, qui interroge autant la stratÃ©gie dâ€™Ubisoft que sa capacitÃ© Ã  piloter efficacement des projets Ã  long terme.
""")

    st.divider()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PAGE 5 : CONCLUSION â€” texte identique au screenshot
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
elif page == "Conclusion":
    st.title("Conclusion")

    st.markdown("""
Lâ€™ensemble des analyses menÃ©es dans ce projet met en lumiÃ¨re un constat clair : la chute dâ€™Ubisoft ne sâ€™explique pas par une crise gÃ©nÃ©ralisÃ©e du secteur du jeu vidÃ©o, mais bien par des faiblesses propres Ã  lâ€™entreprise. Si lâ€™Ã©diteur continue de produire un volume Ã©levÃ© de titres chaque annÃ©e, cette stratÃ©gie ne se traduit plus par une rentabilitÃ© suffisante. Depuis prÃ¨s dâ€™une dÃ©cennie, les signaux dâ€™alerte sont visibles, notamment Ã  travers une rupture croissante entre la promesse marketing des jeux et leur rÃ©ception par les joueurs.


                
Plus prÃ©occupant encore, les projets les plus ambitieux â€” tant en durÃ©e de dÃ©veloppement quâ€™en investissement financier â€” figurent aujourdâ€™hui parmi les plus sÃ©vÃ¨rement critiquÃ©s. Cette anomalie entre les moyens dÃ©ployÃ©s et la qualitÃ© perÃ§ue traduit une perte de cohÃ©rence entre la stratÃ©gie de production et les attentes du marchÃ©.

Dans ce contexte, Ubisoft doit impÃ©rativement repenser deux dimensions centrales de son organisation : sa capacitÃ© Ã  piloter des projets sur le long terme de maniÃ¨re agile et rÃ©aliste, et sa facultÃ© Ã  intÃ©grer de maniÃ¨re proactive les retours et attentes de ses communautÃ©s de joueurs.

Pour inverser cette tendance, plusieurs pistes peuvent Ãªtre envisagÃ©es. Il apparaÃ®t essentiel dâ€™amÃ©liorer lâ€™efficience opÃ©rationnelle en rÃ©-alignant la masse salariale avec les ambitions rÃ©elles et la performance attendue, tout en identifiant les studios ou projets structurellement sous-performants. Il est Ã©galement crucial de mieux valoriser lâ€™engagement des joueurs en exploitant les signaux faibles issus des critiques, des forums ou des donnÃ©es dâ€™usage afin dâ€™orienter les dÃ©cisions produit de maniÃ¨re plus pertinente.

Par ailleurs, Ubisoft gagnerait Ã  repenser ses modÃ¨les Ã©conomiques, en redonnant une place au freemium lorsque cela est pertinent, ou en explorant des formats hybrides comme les abonnements ou les contenus additionnels. Enfin, la dÃ©pendance Ã  des blockbusters Ã  trÃ¨s long dÃ©veloppement devrait Ãªtre rÃ©Ã©valuÃ©e, au profit de cycles plus courts, plus agiles, et potentiellement plus en phase avec les Ã©volutions du marchÃ©                
                """)
    st.divider()
    st.divider()
    

# Annexe mÃ©thodologique â€” petite police + italique
    st.markdown(
    """
    <style>
      .annexe-ux { font-size: 0.92rem; font-style: italic; line-height: 1.55; }
      .annexe-ux h3 { font-size: 1.08rem; font-style: italic; margin: 0 0 0.6rem 0; }
      .annexe-ux p { margin: 0 0 0.6rem 0; }
      .annexe-ux strong { font-style: normal; } /* garder les sous-titres en gras lisibles */
    </style>
    <div class="annexe-ux">
      <h3>Annexe mÃ©thodologique</h3>

      <p>Pour mieux comprendre le dÃ©clin dâ€™Ubisoft, nous avons entrepris une approche en trois volets, mÃªlant analyse financiÃ¨re, exploration des performances des jeux, et Ã©tude de leur rÃ©ception critique.</p>

      <p><strong>I. Une plongÃ©e dans les chiffres : lâ€™analyse financiÃ¨re comparative</strong><br/>
      Notre premiÃ¨re Ã©tape fut de comparer lâ€™Ã©volution boursiÃ¨re dâ€™Ubisoft Ã  celle de deux ETF emblÃ©matiques du secteur : ESPO et HERO. GrÃ¢ce Ã  la plateforme TradingView, nous avons recueilli les donnÃ©es couvrant la pÃ©riode 2018 Ã  2024.<br/>
      Pour les analyser, nous avons mobilisÃ© les capacitÃ©s de LLM couplÃ©es Ã  une recherche documentaire rigoureuse.<br/>
      RÃ©sultat : un jeu de donnÃ©es financier complet, traÃ§ant les courbes de valeur de lâ€™action Ubisoft et de nos deux ETF de rÃ©fÃ©rence.<br/>
      <em>Source : Site TradingView</em><br/>
      <a href="https://fr.tradingview.com/chart/OHym2NDq/?symbol=NASDAQ%3AESPO">ESPO</a> ;
      <a href="https://fr.tradingview.com/chart/OHym2NDq/?symbol=NASDAQ%3AHERO">HERO</a> ;
      <a href="https://fr.tradingview.com/chart/OHym2NDq/?symbol=EUROTLX%3A4UBI">4UBI</a>
      </p>

      <p><strong>II. Explorer les performances concrÃ¨tes : les jeux Ubisoft Ã  la loupe</strong><br/>
      Nous nous sommes ensuite intÃ©ressÃ©s aux performances des jeux publiÃ©s par Ubisoft entre 1995 et 2025.<br/>
      Pour ce faire, nous avons utilisÃ© le site VG Insights, une base de donnÃ©es spÃ©cialisÃ©e, afin dâ€™extraire les informations-clÃ©s : Ã©diteurs, volumes de jeux, etc.<br/>
      Cette extraction a Ã©tÃ© automatisÃ©e grÃ¢ce Ã  des scripts basÃ©s sur BeautifulSoup et Selenium, ce qui nous a permis de constituer deux jeux de donnÃ©es â€“ lâ€™un dÃ©diÃ© aux Ã©diteurs , lâ€™autre aux jeux eux-mÃªmes.<br/>
      <em>Source : Site VG insights :</em><br/>
      <a href="https://vginsights.com/publishers-database">https://vginsights.com/publishers-database</a> &amp;
      <a href="https://vginsights.com/publisher/8/ubisoft">https://vginsights.com/publisher/8/ubisoft</a>
      </p>

      <p><strong>III. Ce que le public en pense : critiques et perception</strong><br/>
      Enfin, pour comprendre la rÃ©ception des jeux Ubisoft par la critique et les joueurs, nous avons scrutÃ© Metacritic, plateforme de rÃ©fÃ©rence dans lâ€™agrÃ©gation de critiques.<br/>
      Nous avons collectÃ© les notes et critiques des jeux Ubisoft sortis entre 1995 et 2025, encore une fois Ã  lâ€™aide de scraping automatisÃ© via BeautifulSoup et Selenium.<br/>
      Cette phase a abouti Ã  la crÃ©ation de deux jeux de donnÃ©es complÃ©mentaires, lâ€™un centrÃ© sur les notes, lâ€™autre sur les commentaires qualitatifs.<br/>
      <em>Source : Site Metacritic :</em><br/>
      <a href="https://www.metacritic.com/browse/game/?releaseYearMin=1995&releaseYearMax=2025&page=1">https://www.metacritic.com/browse/game/?releaseYearMin=1995&amp;releaseYearMax=2025&amp;page=1</a>
      </p>
    </div>
    """,
    unsafe_allow_html=True
)













